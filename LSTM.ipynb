{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in our data (100000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0  1   B001E4KFG0  A3SGXH7AUHU8GW  delmartian                        \n",
       "1  2   B00813GRG4  A1D87F6ZCVE5NK  dll pa                            \n",
       "2  3   B000LQOCH0  ABXLMWJIXXAIN   Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0  1                     1                       1      1303862400   \n",
       "1  0                     0                       0      1346976000   \n",
       "2  1                     1                       1      1219017600   \n",
       "\n",
       "                 Summary  \\\n",
       "0  Good Quality Dog Food   \n",
       "1  Not as Advertised       \n",
       "2  \"Delight\" says it all   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Text  \n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.                                                                                                                                                                                                                                                        \n",
       "1  Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".                                                                                                                                                                                                                                                                                                                                 \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('C:/Users/amit.prakash/Documents/Python/Python/Amazon Food/database.sqlite')\n",
    "filtered_data = pd.read_sql_query(''' SELECT * FROM REVIEWS LIMIT 100000''', conn)\n",
    "\n",
    "# Give reviews with Score>3 a positive rating(1), and reviews with a score<3 a negative rating(0).\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def findMinorClassPoints(df):\n",
    "    posCount = int(df[df['Score']==1].shape[0]);\n",
    "    negCount = int(df[df['Score']==0].shape[0]);\n",
    "    if negCount < posCount:\n",
    "        return negCount\n",
    "    return posCount\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "\n",
    "#Performing Downsampling\n",
    "# samplingCount = findMinorClassPoints(filtered_data)\n",
    "# postive_df = filtered_data[filtered_data['Score'] == 1].sample(n=5000)\n",
    "# negative_df = filtered_data[filtered_data['Score'] == 0].sample(n=5000)\n",
    "\n",
    "# filtered_data = pd.concat([postive_df, negative_df])\n",
    "\n",
    "print(\"Number of data points in our data\", filtered_data.shape)\n",
    "filtered_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 88461/88461 [00:40<00:00, 2184.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 88461/88461 [00:02<00:00, 37321.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape\n",
    "\n",
    "#Removing the anamolies\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "\n",
    "#Preprocessing\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "preprocessed_reviews = []\n",
    "\n",
    "for sentance in tqdm(final['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    # sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sentance.strip())\n",
    "    \n",
    "## Similartly you can do preprocessing for review summary also.\n",
    "def concatenateSummaryWithText(str1, str2):\n",
    "    return str1 + ' ' + str2\n",
    "\n",
    "preprocessed_summary = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentence in tqdm(final['Summary'].values):\n",
    "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
    "    #sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
    "    sentence = decontracted(sentence)\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
    "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    # sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
    "    preprocessed_summary.append(sentence.strip())\n",
    "    \n",
    "preprocessed_reviews = list(map(concatenateSummaryWithText, preprocessed_reviews, preprocessed_summary))\n",
    "final['CleanedText'] = preprocessed_reviews\n",
    "final['CleanedText'] = final['CleanedText'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final['CleanedText']\n",
    "y = final['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final\n",
    "del preprocessed_reviews\n",
    "del preprocessed_summary\n",
    "del sorted_data\n",
    "del filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input  - Train: (56614,)\n",
      "Shape of Output - Train: (56614,)\n",
      "Shape of Input  - CV   : (14154,)\n",
      "Shape of Output - CV   : (14154,)\n",
      "Shape of Input  - Test : (17693,)\n",
      "Shape of Output - Test : (17693,)\n"
     ]
    }
   ],
   "source": [
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.20, stratify=y, shuffle=True)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_t, y_t, test_size=0.20, stratify=y_t, shuffle=True)\n",
    "print(\"Shape of Input  - Train:\", X_train.shape)\n",
    "print(\"Shape of Output - Train:\", y_train.shape)\n",
    "print(\"Shape of Input  - CV   :\", X_cv.shape)\n",
    "print(\"Shape of Output - CV   :\", y_cv.shape)\n",
    "print(\"Shape of Input  - Test :\", X_test.shape)\n",
    "print(\"Shape of Output - Test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[571, 289, 9, 285, 3041, 5, 42, 744, 333, 16, 152, 182, 115, 2, 433, 1, 687, 3, 861, 5, 546, 2506, 2535, 3042, 211, 3, 193, 1235, 349, 357, 546, 1634, 258, 3, 193, 1235, 349, 357]\n",
      "56614\n"
     ]
    }
   ],
   "source": [
    "tokenize = Tokenizer(num_words=5000)\n",
    "tokenize.fit_on_texts(X_train)\n",
    "\n",
    "X_train_new = tokenize.texts_to_sequences(X_train)\n",
    "X_cv_new = tokenize.texts_to_sequences(X_cv)\n",
    "X_test_new = tokenize.texts_to_sequences(X_test)\n",
    "\n",
    "print(X_train_new[1])\n",
    "print(len(X_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56614, 1000)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  571  289    9  285\n",
      " 3041    5   42  744  333   16  152  182  115    2  433    1  687    3\n",
      "  861    5  546 2506 2535 3042  211    3  193 1235  349  357  546 1634\n",
      "  258    3  193 1235  349  357]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1000\n",
    "X_train_new = sequence.pad_sequences(X_train_new, maxlen=max_review_length)\n",
    "X_cv_new = sequence.pad_sequences(X_cv_new, maxlen=max_review_length)\n",
    "X_test_new = sequence.pad_sequences(X_test_new, maxlen=max_review_length)\n",
    "\n",
    "print(X_train_new.shape)\n",
    "print(X_train_new[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with 1 layer and 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amit.prakash\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "***********************************************\n",
      "Printing the Model Summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "***********************************************\n"
     ]
    }
   ],
   "source": [
    "embed_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embed_vector_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"***********************************************\")\n",
    "print(\"Printing the Model Summary\")\n",
    "print(model.summary())\n",
    "print(\"***********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "n_epochs = 5\n",
    "batchsize = 512\n",
    "\n",
    "final_output = pd.DataFrame(columns=[\"Model\", \"Architecture\",\n",
    "                                     \"TRAIN_LOSS\", \"TEST_LOSS\", \"TRAIN_ACC\", \"TEST_ACC\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amit.prakash\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 56614 samples, validate on 14154 samples\n",
      "Epoch 1/5\n",
      "56614/56614 [==============================] - ETA: 22:48 - loss: 0.6930 - acc: 0.53 - ETA: 22:03 - loss: 0.6901 - acc: 0.69 - ETA: 22:14 - loss: 0.6874 - acc: 0.73 - ETA: 23:10 - loss: 0.6845 - acc: 0.76 - ETA: 23:46 - loss: 0.6811 - acc: 0.77 - ETA: 25:12 - loss: 0.6771 - acc: 0.78 - ETA: 26:42 - loss: 0.6723 - acc: 0.79 - ETA: 27:06 - loss: 0.6670 - acc: 0.80 - ETA: 27:07 - loss: 0.6602 - acc: 0.81 - ETA: 27:21 - loss: 0.6531 - acc: 0.81 - ETA: 27:31 - loss: 0.6428 - acc: 0.81 - ETA: 27:41 - loss: 0.6289 - acc: 0.82 - ETA: 27:55 - loss: 0.6135 - acc: 0.82 - ETA: 28:11 - loss: 0.6143 - acc: 0.82 - ETA: 28:18 - loss: 0.6071 - acc: 0.82 - ETA: 28:30 - loss: 0.5960 - acc: 0.82 - ETA: 28:41 - loss: 0.5839 - acc: 0.83 - ETA: 28:53 - loss: 0.5751 - acc: 0.83 - ETA: 29:08 - loss: 0.5669 - acc: 0.83 - ETA: 29:23 - loss: 0.5591 - acc: 0.83 - ETA: 29:54 - loss: 0.5539 - acc: 0.83 - ETA: 29:54 - loss: 0.5480 - acc: 0.83 - ETA: 30:09 - loss: 0.5424 - acc: 0.83 - ETA: 30:17 - loss: 0.5385 - acc: 0.83 - ETA: 30:28 - loss: 0.5358 - acc: 0.83 - ETA: 30:39 - loss: 0.5309 - acc: 0.83 - ETA: 30:43 - loss: 0.5257 - acc: 0.83 - ETA: 30:50 - loss: 0.5225 - acc: 0.83 - ETA: 31:01 - loss: 0.5195 - acc: 0.83 - ETA: 31:07 - loss: 0.5159 - acc: 0.83 - ETA: 31:09 - loss: 0.5132 - acc: 0.83 - ETA: 31:09 - loss: 0.5122 - acc: 0.83 - ETA: 31:18 - loss: 0.5100 - acc: 0.83 - ETA: 31:22 - loss: 0.5057 - acc: 0.83 - ETA: 31:20 - loss: 0.5012 - acc: 0.83 - ETA: 31:16 - loss: 0.4982 - acc: 0.83 - ETA: 31:11 - loss: 0.4947 - acc: 0.83 - ETA: 31:09 - loss: 0.4913 - acc: 0.84 - ETA: 31:03 - loss: 0.4897 - acc: 0.84 - ETA: 30:57 - loss: 0.4868 - acc: 0.84 - ETA: 30:51 - loss: 0.4849 - acc: 0.84 - ETA: 30:46 - loss: 0.4831 - acc: 0.84 - ETA: 30:37 - loss: 0.4800 - acc: 0.84 - ETA: 30:26 - loss: 0.4780 - acc: 0.84 - ETA: 30:22 - loss: 0.4757 - acc: 0.84 - ETA: 30:16 - loss: 0.4736 - acc: 0.84 - ETA: 30:14 - loss: 0.4706 - acc: 0.84 - ETA: 30:04 - loss: 0.4684 - acc: 0.84 - ETA: 29:57 - loss: 0.4654 - acc: 0.84 - ETA: 29:47 - loss: 0.4630 - acc: 0.84 - ETA: 29:36 - loss: 0.4604 - acc: 0.84 - ETA: 29:21 - loss: 0.4584 - acc: 0.84 - ETA: 29:10 - loss: 0.4563 - acc: 0.84 - ETA: 28:59 - loss: 0.4537 - acc: 0.84 - ETA: 28:45 - loss: 0.4526 - acc: 0.84 - ETA: 28:28 - loss: 0.4513 - acc: 0.84 - ETA: 28:11 - loss: 0.4494 - acc: 0.84 - ETA: 27:56 - loss: 0.4477 - acc: 0.84 - ETA: 27:38 - loss: 0.4455 - acc: 0.84 - ETA: 27:20 - loss: 0.4439 - acc: 0.84 - ETA: 27:03 - loss: 0.4420 - acc: 0.84 - ETA: 26:44 - loss: 0.4403 - acc: 0.84 - ETA: 26:27 - loss: 0.4386 - acc: 0.84 - ETA: 26:06 - loss: 0.4366 - acc: 0.84 - ETA: 25:43 - loss: 0.4345 - acc: 0.84 - ETA: 25:19 - loss: 0.4321 - acc: 0.84 - ETA: 24:57 - loss: 0.4299 - acc: 0.84 - ETA: 24:31 - loss: 0.4281 - acc: 0.84 - ETA: 24:08 - loss: 0.4265 - acc: 0.84 - ETA: 23:44 - loss: 0.4242 - acc: 0.84 - ETA: 23:18 - loss: 0.4224 - acc: 0.84 - ETA: 22:55 - loss: 0.4209 - acc: 0.84 - ETA: 22:27 - loss: 0.4190 - acc: 0.84 - ETA: 22:01 - loss: 0.4170 - acc: 0.84 - ETA: 21:33 - loss: 0.4149 - acc: 0.84 - ETA: 21:06 - loss: 0.4128 - acc: 0.85 - ETA: 20:39 - loss: 0.4112 - acc: 0.85 - ETA: 20:09 - loss: 0.4097 - acc: 0.85 - ETA: 19:39 - loss: 0.4084 - acc: 0.85 - ETA: 19:08 - loss: 0.4069 - acc: 0.85 - ETA: 18:38 - loss: 0.4054 - acc: 0.85 - ETA: 18:06 - loss: 0.4034 - acc: 0.85 - ETA: 17:36 - loss: 0.4013 - acc: 0.85 - ETA: 17:03 - loss: 0.3998 - acc: 0.85 - ETA: 16:31 - loss: 0.3983 - acc: 0.85 - ETA: 15:58 - loss: 0.3969 - acc: 0.85 - ETA: 15:23 - loss: 0.3957 - acc: 0.85 - ETA: 14:49 - loss: 0.3939 - acc: 0.85 - ETA: 14:13 - loss: 0.3925 - acc: 0.85 - ETA: 13:39 - loss: 0.3907 - acc: 0.85 - ETA: 13:02 - loss: 0.3887 - acc: 0.85 - ETA: 12:27 - loss: 0.3867 - acc: 0.85 - ETA: 11:50 - loss: 0.3849 - acc: 0.85 - ETA: 11:13 - loss: 0.3830 - acc: 0.85 - ETA: 10:36 - loss: 0.3819 - acc: 0.85 - ETA: 9:58 - loss: 0.3803 - acc: 0.8588 - ETA: 9:19 - loss: 0.3787 - acc: 0.859 - ETA: 8:40 - loss: 0.3770 - acc: 0.859 - ETA: 8:01 - loss: 0.3753 - acc: 0.860 - ETA: 7:21 - loss: 0.3738 - acc: 0.860 - ETA: 6:41 - loss: 0.3722 - acc: 0.861 - ETA: 6:01 - loss: 0.3707 - acc: 0.861 - ETA: 5:20 - loss: 0.3694 - acc: 0.862 - ETA: 4:39 - loss: 0.3677 - acc: 0.862 - ETA: 3:58 - loss: 0.3666 - acc: 0.862 - ETA: 3:16 - loss: 0.3651 - acc: 0.863 - ETA: 2:34 - loss: 0.3640 - acc: 0.863 - ETA: 1:51 - loss: 0.3622 - acc: 0.864 - ETA: 1:08 - loss: 0.3609 - acc: 0.864 - ETA: 25s - loss: 0.3598 - acc: 0.864 - 5033s 89ms/step - loss: 0.3590 - acc: 0.8652 - val_loss: 0.2170 - val_acc: 0.9086\n",
      "Epoch 2/5\n",
      "56614/56614 [==============================] - ETA: 1:57:55 - loss: 0.1946 - acc: 0.92 - ETA: 1:52:40 - loss: 0.2099 - acc: 0.90 - ETA: 1:52:12 - loss: 0.2059 - acc: 0.91 - ETA: 1:50:32 - loss: 0.2069 - acc: 0.91 - ETA: 1:50:58 - loss: 0.1996 - acc: 0.91 - ETA: 1:51:35 - loss: 0.1990 - acc: 0.91 - ETA: 1:51:39 - loss: 0.2045 - acc: 0.91 - ETA: 1:49:58 - loss: 0.2036 - acc: 0.91 - ETA: 1:48:39 - loss: 0.2003 - acc: 0.91 - ETA: 1:47:10 - loss: 0.1954 - acc: 0.91 - ETA: 1:45:51 - loss: 0.1927 - acc: 0.92 - ETA: 1:44:59 - loss: 0.1925 - acc: 0.92 - ETA: 1:43:48 - loss: 0.1933 - acc: 0.92 - ETA: 1:43:05 - loss: 0.1929 - acc: 0.92 - ETA: 1:41:49 - loss: 0.1925 - acc: 0.92 - ETA: 1:41:30 - loss: 0.1935 - acc: 0.92 - ETA: 1:40:48 - loss: 0.1942 - acc: 0.92 - ETA: 1:40:06 - loss: 0.1939 - acc: 0.92 - ETA: 1:38:57 - loss: 0.1951 - acc: 0.92 - ETA: 1:37:50 - loss: 0.1938 - acc: 0.92 - ETA: 1:36:51 - loss: 0.1933 - acc: 0.92 - ETA: 1:35:41 - loss: 0.1922 - acc: 0.92 - ETA: 1:34:51 - loss: 0.1917 - acc: 0.92 - ETA: 1:33:47 - loss: 0.1902 - acc: 0.92 - ETA: 1:32:54 - loss: 0.1895 - acc: 0.92 - ETA: 1:31:50 - loss: 0.1889 - acc: 0.92 - ETA: 1:30:47 - loss: 0.1894 - acc: 0.92 - ETA: 1:29:41 - loss: 0.1880 - acc: 0.92 - ETA: 1:28:32 - loss: 0.1881 - acc: 0.92 - ETA: 1:27:24 - loss: 0.1867 - acc: 0.92 - ETA: 1:26:37 - loss: 0.1872 - acc: 0.92 - ETA: 1:25:49 - loss: 0.1878 - acc: 0.92 - ETA: 1:24:40 - loss: 0.1880 - acc: 0.92 - ETA: 1:23:43 - loss: 0.1878 - acc: 0.92 - ETA: 1:22:38 - loss: 0.1881 - acc: 0.92 - ETA: 1:21:35 - loss: 0.1881 - acc: 0.92 - ETA: 1:20:34 - loss: 0.1885 - acc: 0.92 - ETA: 1:19:33 - loss: 0.1885 - acc: 0.92 - ETA: 1:18:22 - loss: 0.1882 - acc: 0.92 - ETA: 1:17:16 - loss: 0.1886 - acc: 0.92 - ETA: 1:16:18 - loss: 0.1884 - acc: 0.92 - ETA: 1:15:10 - loss: 0.1887 - acc: 0.92 - ETA: 1:14:13 - loss: 0.1890 - acc: 0.92 - ETA: 1:13:12 - loss: 0.1896 - acc: 0.92 - ETA: 1:12:09 - loss: 0.1896 - acc: 0.92 - ETA: 1:11:04 - loss: 0.1891 - acc: 0.92 - ETA: 1:10:00 - loss: 0.1893 - acc: 0.92 - ETA: 1:08:54 - loss: 0.1889 - acc: 0.92 - ETA: 1:07:52 - loss: 0.1888 - acc: 0.92 - ETA: 1:06:44 - loss: 0.1888 - acc: 0.92 - ETA: 1:05:45 - loss: 0.1893 - acc: 0.92 - ETA: 1:04:43 - loss: 0.1894 - acc: 0.92 - ETA: 1:03:34 - loss: 0.1889 - acc: 0.92 - ETA: 1:02:30 - loss: 0.1886 - acc: 0.92 - ETA: 1:01:26 - loss: 0.1885 - acc: 0.92 - ETA: 1:00:23 - loss: 0.1888 - acc: 0.92 - ETA: 59:18 - loss: 0.1883 - acc: 0.9237 - ETA: 58:12 - loss: 0.1881 - acc: 0.92 - ETA: 57:04 - loss: 0.1885 - acc: 0.92 - ETA: 56:03 - loss: 0.1885 - acc: 0.92 - ETA: 54:57 - loss: 0.1884 - acc: 0.92 - ETA: 53:51 - loss: 0.1885 - acc: 0.92 - ETA: 52:45 - loss: 0.1889 - acc: 0.92 - ETA: 51:39 - loss: 0.1890 - acc: 0.92 - ETA: 50:35 - loss: 0.1888 - acc: 0.92 - ETA: 49:27 - loss: 0.1885 - acc: 0.92 - ETA: 48:23 - loss: 0.1889 - acc: 0.92 - ETA: 47:16 - loss: 0.1885 - acc: 0.92 - ETA: 46:20 - loss: 0.1886 - acc: 0.92 - ETA: 45:27 - loss: 0.1887 - acc: 0.92 - ETA: 44:32 - loss: 0.1888 - acc: 0.92 - ETA: 43:37 - loss: 0.1889 - acc: 0.92 - ETA: 42:40 - loss: 0.1888 - acc: 0.92 - ETA: 41:38 - loss: 0.1883 - acc: 0.92 - ETA: 40:35 - loss: 0.1883 - acc: 0.92 - ETA: 39:34 - loss: 0.1881 - acc: 0.92 - ETA: 38:34 - loss: 0.1884 - acc: 0.92 - ETA: 37:33 - loss: 0.1881 - acc: 0.92 - ETA: 36:30 - loss: 0.1887 - acc: 0.92 - ETA: 35:24 - loss: 0.1885 - acc: 0.92 - ETA: 34:24 - loss: 0.1885 - acc: 0.92 - ETA: 33:21 - loss: 0.1881 - acc: 0.92 - ETA: 32:16 - loss: 0.1882 - acc: 0.92 - ETA: 31:13 - loss: 0.1877 - acc: 0.92 - ETA: 30:10 - loss: 0.1878 - acc: 0.92 - ETA: 29:03 - loss: 0.1875 - acc: 0.92 - ETA: 27:53 - loss: 0.1873 - acc: 0.92 - ETA: 26:45 - loss: 0.1869 - acc: 0.92 - ETA: 25:35 - loss: 0.1866 - acc: 0.92 - ETA: 24:23 - loss: 0.1866 - acc: 0.92 - ETA: 23:13 - loss: 0.1866 - acc: 0.92 - ETA: 22:02 - loss: 0.1870 - acc: 0.92 - ETA: 20:51 - loss: 0.1872 - acc: 0.92 - ETA: 19:39 - loss: 0.1867 - acc: 0.92 - ETA: 18:27 - loss: 0.1871 - acc: 0.92 - ETA: 17:16 - loss: 0.1873 - acc: 0.92 - ETA: 16:04 - loss: 0.1872 - acc: 0.92 - ETA: 14:53 - loss: 0.1872 - acc: 0.92 - ETA: 13:42 - loss: 0.1872 - acc: 0.92 - ETA: 12:31 - loss: 0.1868 - acc: 0.92 - ETA: 11:20 - loss: 0.1869 - acc: 0.92 - ETA: 10:09 - loss: 0.1869 - acc: 0.92 - ETA: 8:58 - loss: 0.1868 - acc: 0.9242 - ETA: 7:46 - loss: 0.1869 - acc: 0.924 - ETA: 6:35 - loss: 0.1865 - acc: 0.924 - ETA: 5:24 - loss: 0.1865 - acc: 0.924 - ETA: 4:13 - loss: 0.1861 - acc: 0.924 - ETA: 3:02 - loss: 0.1860 - acc: 0.924 - ETA: 1:51 - loss: 0.1862 - acc: 0.924 - ETA: 40s - loss: 0.1860 - acc: 0.924 - 8058s 142ms/step - loss: 0.1859 - acc: 0.9246 - val_loss: 0.1917 - val_acc: 0.9183\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56614/56614 [==============================] - ETA: 2:06:53 - loss: 0.1320 - acc: 0.95 - ETA: 2:08:04 - loss: 0.1435 - acc: 0.94 - ETA: 2:06:35 - loss: 0.1513 - acc: 0.94 - ETA: 2:06:40 - loss: 0.1511 - acc: 0.94 - ETA: 2:06:33 - loss: 0.1533 - acc: 0.94 - ETA: 2:04:23 - loss: 0.1510 - acc: 0.94 - ETA: 2:02:30 - loss: 0.1471 - acc: 0.94 - ETA: 2:00:52 - loss: 0.1472 - acc: 0.94 - ETA: 1:59:25 - loss: 0.1463 - acc: 0.94 - ETA: 1:58:10 - loss: 0.1493 - acc: 0.94 - ETA: 1:57:44 - loss: 0.1511 - acc: 0.94 - ETA: 1:55:56 - loss: 0.1521 - acc: 0.94 - ETA: 1:54:57 - loss: 0.1517 - acc: 0.94 - ETA: 1:53:30 - loss: 0.1499 - acc: 0.94 - ETA: 1:52:29 - loss: 0.1531 - acc: 0.94 - ETA: 1:51:29 - loss: 0.1524 - acc: 0.94 - ETA: 1:50:38 - loss: 0.1528 - acc: 0.94 - ETA: 1:49:07 - loss: 0.1527 - acc: 0.94 - ETA: 1:47:41 - loss: 0.1548 - acc: 0.94 - ETA: 1:46:32 - loss: 0.1566 - acc: 0.93 - ETA: 1:45:14 - loss: 0.1567 - acc: 0.93 - ETA: 1:44:19 - loss: 0.1575 - acc: 0.93 - ETA: 1:43:17 - loss: 0.1575 - acc: 0.93 - ETA: 1:42:03 - loss: 0.1587 - acc: 0.93 - ETA: 1:40:57 - loss: 0.1594 - acc: 0.93 - ETA: 1:39:53 - loss: 0.1582 - acc: 0.93 - ETA: 1:38:46 - loss: 0.1580 - acc: 0.93 - ETA: 1:37:36 - loss: 0.1581 - acc: 0.93 - ETA: 1:36:22 - loss: 0.1579 - acc: 0.93 - ETA: 1:35:14 - loss: 0.1580 - acc: 0.93 - ETA: 1:33:59 - loss: 0.1588 - acc: 0.93 - ETA: 1:32:45 - loss: 0.1595 - acc: 0.93 - ETA: 1:31:38 - loss: 0.1595 - acc: 0.93 - ETA: 1:30:41 - loss: 0.1582 - acc: 0.93 - ETA: 1:29:37 - loss: 0.1576 - acc: 0.93 - ETA: 1:28:37 - loss: 0.1574 - acc: 0.93 - ETA: 1:27:32 - loss: 0.1579 - acc: 0.93 - ETA: 1:26:16 - loss: 0.1576 - acc: 0.93 - ETA: 1:25:05 - loss: 0.1575 - acc: 0.93 - ETA: 1:23:55 - loss: 0.1570 - acc: 0.93 - ETA: 1:22:42 - loss: 0.1569 - acc: 0.93 - ETA: 1:21:33 - loss: 0.1571 - acc: 0.93 - ETA: 1:20:26 - loss: 0.1577 - acc: 0.93 - ETA: 1:19:15 - loss: 0.1577 - acc: 0.93 - ETA: 1:18:00 - loss: 0.1581 - acc: 0.93 - ETA: 1:16:56 - loss: 0.1584 - acc: 0.93 - ETA: 1:15:51 - loss: 0.1583 - acc: 0.93 - ETA: 1:14:40 - loss: 0.1583 - acc: 0.93 - ETA: 1:13:33 - loss: 0.1584 - acc: 0.93 - ETA: 1:12:20 - loss: 0.1582 - acc: 0.93 - ETA: 1:11:10 - loss: 0.1584 - acc: 0.93 - ETA: 1:09:59 - loss: 0.1588 - acc: 0.93 - ETA: 1:08:50 - loss: 0.1584 - acc: 0.93 - ETA: 1:07:44 - loss: 0.1585 - acc: 0.93 - ETA: 1:06:28 - loss: 0.1590 - acc: 0.93 - ETA: 1:05:17 - loss: 0.1584 - acc: 0.93 - ETA: 1:04:02 - loss: 0.1588 - acc: 0.93 - ETA: 1:02:59 - loss: 0.1598 - acc: 0.93 - ETA: 1:01:53 - loss: 0.1596 - acc: 0.93 - ETA: 1:00:50 - loss: 0.1589 - acc: 0.93 - ETA: 59:40 - loss: 0.1598 - acc: 0.9373 - ETA: 58:25 - loss: 0.1599 - acc: 0.93 - ETA: 57:12 - loss: 0.1603 - acc: 0.93 - ETA: 56:00 - loss: 0.1603 - acc: 0.93 - ETA: 54:45 - loss: 0.1601 - acc: 0.93 - ETA: 53:36 - loss: 0.1610 - acc: 0.93 - ETA: 52:22 - loss: 0.1609 - acc: 0.93 - ETA: 51:12 - loss: 0.1611 - acc: 0.93 - ETA: 50:01 - loss: 0.1609 - acc: 0.93 - ETA: 48:51 - loss: 0.1612 - acc: 0.93 - ETA: 47:35 - loss: 0.1613 - acc: 0.93 - ETA: 46:20 - loss: 0.1612 - acc: 0.93 - ETA: 45:11 - loss: 0.1608 - acc: 0.93 - ETA: 43:58 - loss: 0.1604 - acc: 0.93 - ETA: 42:45 - loss: 0.1605 - acc: 0.93 - ETA: 41:31 - loss: 0.1606 - acc: 0.93 - ETA: 40:17 - loss: 0.1605 - acc: 0.93 - ETA: 39:03 - loss: 0.1606 - acc: 0.93 - ETA: 37:51 - loss: 0.1610 - acc: 0.93 - ETA: 36:37 - loss: 0.1617 - acc: 0.93 - ETA: 35:24 - loss: 0.1616 - acc: 0.93 - ETA: 34:12 - loss: 0.1621 - acc: 0.93 - ETA: 32:59 - loss: 0.1621 - acc: 0.93 - ETA: 31:46 - loss: 0.1620 - acc: 0.93 - ETA: 30:33 - loss: 0.1619 - acc: 0.93 - ETA: 29:20 - loss: 0.1614 - acc: 0.93 - ETA: 28:07 - loss: 0.1612 - acc: 0.93 - ETA: 26:56 - loss: 0.1610 - acc: 0.93 - ETA: 25:44 - loss: 0.1610 - acc: 0.93 - ETA: 24:33 - loss: 0.1611 - acc: 0.93 - ETA: 23:20 - loss: 0.1613 - acc: 0.93 - ETA: 22:08 - loss: 0.1613 - acc: 0.93 - ETA: 20:56 - loss: 0.1611 - acc: 0.93 - ETA: 19:44 - loss: 0.1617 - acc: 0.93 - ETA: 18:33 - loss: 0.1615 - acc: 0.93 - ETA: 17:21 - loss: 0.1613 - acc: 0.93 - ETA: 16:09 - loss: 0.1612 - acc: 0.93 - ETA: 14:57 - loss: 0.1611 - acc: 0.93 - ETA: 13:45 - loss: 0.1608 - acc: 0.93 - ETA: 12:34 - loss: 0.1608 - acc: 0.93 - ETA: 11:23 - loss: 0.1609 - acc: 0.93 - ETA: 10:11 - loss: 0.1609 - acc: 0.93 - ETA: 9:00 - loss: 0.1609 - acc: 0.9361 - ETA: 7:49 - loss: 0.1609 - acc: 0.936 - ETA: 6:38 - loss: 0.1609 - acc: 0.936 - ETA: 5:26 - loss: 0.1612 - acc: 0.935 - ETA: 4:15 - loss: 0.1610 - acc: 0.936 - ETA: 3:03 - loss: 0.1612 - acc: 0.935 - ETA: 1:52 - loss: 0.1614 - acc: 0.935 - ETA: 41s - loss: 0.1611 - acc: 0.935 - 8107s 143ms/step - loss: 0.1610 - acc: 0.9358 - val_loss: 0.1931 - val_acc: 0.9207\n",
      "Epoch 4/5\n",
      "56614/56614 [==============================] - ETA: 2:11:54 - loss: 0.1194 - acc: 0.94 - ETA: 2:14:31 - loss: 0.1241 - acc: 0.94 - ETA: 2:10:10 - loss: 0.1267 - acc: 0.94 - ETA: 2:07:21 - loss: 0.1279 - acc: 0.94 - ETA: 2:04:26 - loss: 0.1315 - acc: 0.94 - ETA: 2:03:22 - loss: 0.1309 - acc: 0.94 - ETA: 2:03:35 - loss: 0.1280 - acc: 0.94 - ETA: 2:01:34 - loss: 0.1355 - acc: 0.94 - ETA: 1:59:31 - loss: 0.1413 - acc: 0.94 - ETA: 1:58:13 - loss: 0.1412 - acc: 0.94 - ETA: 1:56:44 - loss: 0.1426 - acc: 0.94 - ETA: 1:56:22 - loss: 0.1444 - acc: 0.94 - ETA: 1:54:57 - loss: 0.1443 - acc: 0.94 - ETA: 1:53:16 - loss: 0.1441 - acc: 0.94 - ETA: 1:52:28 - loss: 0.1465 - acc: 0.94 - ETA: 1:51:30 - loss: 0.1461 - acc: 0.94 - ETA: 1:50:06 - loss: 0.1453 - acc: 0.94 - ETA: 1:49:37 - loss: 0.1453 - acc: 0.94 - ETA: 1:48:04 - loss: 0.1456 - acc: 0.94 - ETA: 1:47:00 - loss: 0.1455 - acc: 0.94 - ETA: 1:45:47 - loss: 0.1462 - acc: 0.94 - ETA: 1:44:47 - loss: 0.1466 - acc: 0.94 - ETA: 1:43:34 - loss: 0.1465 - acc: 0.94 - ETA: 1:42:11 - loss: 0.1457 - acc: 0.94 - ETA: 1:41:21 - loss: 0.1453 - acc: 0.94 - ETA: 1:40:09 - loss: 0.1449 - acc: 0.94 - ETA: 1:39:00 - loss: 0.1450 - acc: 0.94 - ETA: 1:37:36 - loss: 0.1459 - acc: 0.94 - ETA: 1:36:19 - loss: 0.1455 - acc: 0.94 - ETA: 1:35:06 - loss: 0.1442 - acc: 0.94 - ETA: 1:33:50 - loss: 0.1449 - acc: 0.94 - ETA: 1:32:31 - loss: 0.1445 - acc: 0.94 - ETA: 1:31:14 - loss: 0.1457 - acc: 0.94 - ETA: 1:30:18 - loss: 0.1457 - acc: 0.94 - ETA: 1:29:06 - loss: 0.1465 - acc: 0.94 - ETA: 1:28:06 - loss: 0.1461 - acc: 0.94 - ETA: 1:26:57 - loss: 0.1457 - acc: 0.94 - ETA: 1:25:45 - loss: 0.1467 - acc: 0.94 - ETA: 1:24:40 - loss: 0.1465 - acc: 0.94 - ETA: 1:23:32 - loss: 0.1462 - acc: 0.94 - ETA: 1:22:18 - loss: 0.1460 - acc: 0.94 - ETA: 1:21:09 - loss: 0.1461 - acc: 0.94 - ETA: 1:19:59 - loss: 0.1468 - acc: 0.94 - ETA: 1:18:49 - loss: 0.1473 - acc: 0.94 - ETA: 1:17:35 - loss: 0.1474 - acc: 0.94 - ETA: 1:16:25 - loss: 0.1475 - acc: 0.94 - ETA: 1:15:10 - loss: 0.1470 - acc: 0.94 - ETA: 1:14:00 - loss: 0.1473 - acc: 0.94 - ETA: 1:12:45 - loss: 0.1471 - acc: 0.94 - ETA: 1:11:34 - loss: 0.1469 - acc: 0.94 - ETA: 1:10:25 - loss: 0.1475 - acc: 0.94 - ETA: 1:09:13 - loss: 0.1472 - acc: 0.94 - ETA: 1:08:06 - loss: 0.1472 - acc: 0.94 - ETA: 1:06:52 - loss: 0.1477 - acc: 0.94 - ETA: 1:05:37 - loss: 0.1472 - acc: 0.94 - ETA: 1:04:25 - loss: 0.1476 - acc: 0.94 - ETA: 1:03:15 - loss: 0.1477 - acc: 0.94 - ETA: 1:02:04 - loss: 0.1480 - acc: 0.94 - ETA: 1:00:55 - loss: 0.1482 - acc: 0.94 - ETA: 59:43 - loss: 0.1479 - acc: 0.9411 - ETA: 58:30 - loss: 0.1474 - acc: 0.94 - ETA: 57:19 - loss: 0.1478 - acc: 0.94 - ETA: 56:06 - loss: 0.1481 - acc: 0.94 - ETA: 54:53 - loss: 0.1483 - acc: 0.94 - ETA: 53:43 - loss: 0.1482 - acc: 0.94 - ETA: 52:32 - loss: 0.1484 - acc: 0.94 - ETA: 51:19 - loss: 0.1482 - acc: 0.94 - ETA: 50:07 - loss: 0.1486 - acc: 0.94 - ETA: 48:55 - loss: 0.1485 - acc: 0.94 - ETA: 47:42 - loss: 0.1484 - acc: 0.94 - ETA: 46:31 - loss: 0.1483 - acc: 0.94 - ETA: 45:20 - loss: 0.1483 - acc: 0.94 - ETA: 44:08 - loss: 0.1480 - acc: 0.94 - ETA: 42:58 - loss: 0.1480 - acc: 0.94 - ETA: 41:49 - loss: 0.1482 - acc: 0.94 - ETA: 40:37 - loss: 0.1483 - acc: 0.94 - ETA: 39:27 - loss: 0.1482 - acc: 0.94 - ETA: 38:15 - loss: 0.1484 - acc: 0.94 - ETA: 37:04 - loss: 0.1483 - acc: 0.94 - ETA: 35:53 - loss: 0.1483 - acc: 0.94 - ETA: 34:44 - loss: 0.1488 - acc: 0.94 - ETA: 33:35 - loss: 0.1485 - acc: 0.94 - ETA: 32:24 - loss: 0.1485 - acc: 0.94 - ETA: 31:13 - loss: 0.1488 - acc: 0.94 - ETA: 30:03 - loss: 0.1490 - acc: 0.94 - ETA: 28:53 - loss: 0.1489 - acc: 0.94 - ETA: 27:41 - loss: 0.1488 - acc: 0.94 - ETA: 26:31 - loss: 0.1490 - acc: 0.94 - ETA: 25:22 - loss: 0.1490 - acc: 0.94 - ETA: 24:12 - loss: 0.1491 - acc: 0.94 - ETA: 23:01 - loss: 0.1489 - acc: 0.94 - ETA: 21:51 - loss: 0.1491 - acc: 0.94 - ETA: 20:40 - loss: 0.1493 - acc: 0.93 - ETA: 19:30 - loss: 0.1495 - acc: 0.93 - ETA: 18:20 - loss: 0.1499 - acc: 0.93 - ETA: 17:09 - loss: 0.1497 - acc: 0.93 - ETA: 15:59 - loss: 0.1496 - acc: 0.93 - ETA: 14:48 - loss: 0.1493 - acc: 0.94 - ETA: 13:37 - loss: 0.1493 - acc: 0.94 - ETA: 12:26 - loss: 0.1496 - acc: 0.93 - ETA: 11:15 - loss: 0.1497 - acc: 0.93 - ETA: 10:05 - loss: 0.1500 - acc: 0.93 - ETA: 8:54 - loss: 0.1500 - acc: 0.9395 - ETA: 7:43 - loss: 0.1499 - acc: 0.939 - ETA: 6:33 - loss: 0.1500 - acc: 0.939 - ETA: 5:22 - loss: 0.1499 - acc: 0.939 - ETA: 4:11 - loss: 0.1501 - acc: 0.939 - ETA: 3:01 - loss: 0.1502 - acc: 0.939 - ETA: 1:50 - loss: 0.1502 - acc: 0.939 - ETA: 40s - loss: 0.1501 - acc: 0.939 - 8007s 141ms/step - loss: 0.1501 - acc: 0.9395 - val_loss: 0.2057 - val_acc: 0.9216\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56614/56614 [==============================] - ETA: 2:07:16 - loss: 0.1605 - acc: 0.93 - ETA: 2:06:03 - loss: 0.1603 - acc: 0.93 - ETA: 2:05:26 - loss: 0.1468 - acc: 0.94 - ETA: 2:03:18 - loss: 0.1453 - acc: 0.94 - ETA: 2:03:06 - loss: 0.1466 - acc: 0.94 - ETA: 2:01:47 - loss: 0.1406 - acc: 0.94 - ETA: 2:00:14 - loss: 0.1400 - acc: 0.94 - ETA: 1:58:30 - loss: 0.1406 - acc: 0.94 - ETA: 1:57:16 - loss: 0.1401 - acc: 0.94 - ETA: 1:57:47 - loss: 0.1385 - acc: 0.94 - ETA: 1:56:49 - loss: 0.1370 - acc: 0.94 - ETA: 1:55:36 - loss: 0.1374 - acc: 0.94 - ETA: 1:54:35 - loss: 0.1380 - acc: 0.94 - ETA: 1:53:57 - loss: 0.1397 - acc: 0.94 - ETA: 1:52:39 - loss: 0.1381 - acc: 0.94 - ETA: 1:51:23 - loss: 0.1354 - acc: 0.94 - ETA: 1:49:52 - loss: 0.1363 - acc: 0.94 - ETA: 1:48:36 - loss: 0.1363 - acc: 0.94 - ETA: 1:47:23 - loss: 0.1353 - acc: 0.94 - ETA: 1:46:27 - loss: 0.1352 - acc: 0.94 - ETA: 1:45:13 - loss: 0.1349 - acc: 0.94 - ETA: 1:44:15 - loss: 0.1349 - acc: 0.94 - ETA: 1:42:56 - loss: 0.1361 - acc: 0.94 - ETA: 1:41:38 - loss: 0.1363 - acc: 0.94 - ETA: 1:40:17 - loss: 0.1361 - acc: 0.94 - ETA: 1:39:05 - loss: 0.1367 - acc: 0.94 - ETA: 1:38:11 - loss: 0.1366 - acc: 0.94 - ETA: 1:36:52 - loss: 0.1374 - acc: 0.94 - ETA: 1:35:32 - loss: 0.1378 - acc: 0.94 - ETA: 1:34:34 - loss: 0.1370 - acc: 0.94 - ETA: 1:33:22 - loss: 0.1387 - acc: 0.94 - ETA: 1:32:19 - loss: 0.1380 - acc: 0.94 - ETA: 1:31:06 - loss: 0.1381 - acc: 0.94 - ETA: 1:29:59 - loss: 0.1390 - acc: 0.94 - ETA: 1:28:54 - loss: 0.1386 - acc: 0.94 - ETA: 1:27:37 - loss: 0.1385 - acc: 0.94 - ETA: 1:26:49 - loss: 0.1383 - acc: 0.94 - ETA: 1:25:48 - loss: 0.1381 - acc: 0.94 - ETA: 1:24:35 - loss: 0.1372 - acc: 0.94 - ETA: 1:24:39 - loss: 0.1369 - acc: 0.94 - ETA: 1:25:48 - loss: 0.1366 - acc: 0.94 - ETA: 1:24:53 - loss: 0.1364 - acc: 0.94 - ETA: 1:24:17 - loss: 0.1364 - acc: 0.94 - ETA: 1:24:41 - loss: 0.1364 - acc: 0.94 - ETA: 1:23:43 - loss: 0.1361 - acc: 0.94 - ETA: 1:22:40 - loss: 0.1368 - acc: 0.94 - ETA: 1:22:25 - loss: 0.1370 - acc: 0.94 - ETA: 1:21:01 - loss: 0.1371 - acc: 0.94 - ETA: 1:20:04 - loss: 0.1376 - acc: 0.94 - ETA: 1:18:58 - loss: 0.1376 - acc: 0.94 - ETA: 1:17:38 - loss: 0.1378 - acc: 0.94 - ETA: 1:16:23 - loss: 0.1377 - acc: 0.94 - ETA: 1:14:59 - loss: 0.1372 - acc: 0.94 - ETA: 1:13:44 - loss: 0.1373 - acc: 0.94 - ETA: 1:12:23 - loss: 0.1374 - acc: 0.94 - ETA: 1:11:03 - loss: 0.1379 - acc: 0.94 - ETA: 1:09:41 - loss: 0.1381 - acc: 0.94 - ETA: 1:08:15 - loss: 0.1384 - acc: 0.94 - ETA: 1:06:55 - loss: 0.1387 - acc: 0.94 - ETA: 1:05:30 - loss: 0.1384 - acc: 0.94 - ETA: 1:04:10 - loss: 0.1389 - acc: 0.94 - ETA: 1:02:49 - loss: 0.1387 - acc: 0.94 - ETA: 1:01:24 - loss: 0.1396 - acc: 0.94 - ETA: 1:00:00 - loss: 0.1398 - acc: 0.94 - ETA: 58:40 - loss: 0.1397 - acc: 0.9456 - ETA: 57:17 - loss: 0.1400 - acc: 0.94 - ETA: 56:02 - loss: 0.1405 - acc: 0.94 - ETA: 54:47 - loss: 0.1407 - acc: 0.94 - ETA: 53:26 - loss: 0.1408 - acc: 0.94 - ETA: 52:09 - loss: 0.1409 - acc: 0.94 - ETA: 50:48 - loss: 0.1408 - acc: 0.94 - ETA: 49:27 - loss: 0.1406 - acc: 0.94 - ETA: 48:09 - loss: 0.1409 - acc: 0.94 - ETA: 46:48 - loss: 0.1407 - acc: 0.94 - ETA: 45:28 - loss: 0.1406 - acc: 0.94 - ETA: 44:12 - loss: 0.1408 - acc: 0.94 - ETA: 42:58 - loss: 0.1404 - acc: 0.94 - ETA: 41:39 - loss: 0.1405 - acc: 0.94 - ETA: 40:20 - loss: 0.1408 - acc: 0.94 - ETA: 39:01 - loss: 0.1409 - acc: 0.94 - ETA: 37:45 - loss: 0.1406 - acc: 0.94 - ETA: 36:27 - loss: 0.1410 - acc: 0.94 - ETA: 35:13 - loss: 0.1414 - acc: 0.94 - ETA: 33:58 - loss: 0.1415 - acc: 0.94 - ETA: 32:41 - loss: 0.1414 - acc: 0.94 - ETA: 31:28 - loss: 0.1417 - acc: 0.94 - ETA: 30:11 - loss: 0.1420 - acc: 0.94 - ETA: 28:52 - loss: 0.1421 - acc: 0.94 - ETA: 27:38 - loss: 0.1423 - acc: 0.94 - ETA: 26:20 - loss: 0.1426 - acc: 0.94 - ETA: 25:06 - loss: 0.1424 - acc: 0.94 - ETA: 23:48 - loss: 0.1424 - acc: 0.94 - ETA: 22:31 - loss: 0.1428 - acc: 0.94 - ETA: 21:15 - loss: 0.1426 - acc: 0.94 - ETA: 19:59 - loss: 0.1424 - acc: 0.94 - ETA: 18:42 - loss: 0.1425 - acc: 0.94 - ETA: 17:25 - loss: 0.1426 - acc: 0.94 - ETA: 16:09 - loss: 0.1424 - acc: 0.94 - ETA: 14:51 - loss: 0.1428 - acc: 0.94 - ETA: 13:35 - loss: 0.1427 - acc: 0.94 - ETA: 12:18 - loss: 0.1428 - acc: 0.94 - ETA: 11:01 - loss: 0.1431 - acc: 0.94 - ETA: 9:44 - loss: 0.1431 - acc: 0.9438 - ETA: 8:26 - loss: 0.1430 - acc: 0.943 - ETA: 7:09 - loss: 0.1433 - acc: 0.943 - ETA: 5:52 - loss: 0.1434 - acc: 0.943 - ETA: 4:35 - loss: 0.1434 - acc: 0.943 - ETA: 3:18 - loss: 0.1438 - acc: 0.943 - ETA: 2:01 - loss: 0.1439 - acc: 0.943 - ETA: 44s - loss: 0.1440 - acc: 0.943 - 8749s 155ms/step - loss: 0.1442 - acc: 0.9431 - val_loss: 0.1986 - val_acc: 0.9214\n",
      "17693/17693 [==============================] - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 57s - ETA: 48 - ETA: 40 - ETA: 31 - ETA: 22 - ETA: 13 - ETA: 4 - 305s 17ms/step\n",
      "Test score: 0.20402363778417218\n",
      "Test accuracy: 0.9207031029321661\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_hist = model.fit(X_train_new, y_train, epochs=n_epochs, \n",
    "                   batch_size=batchsize, verbose=1, validation_data=(X_cv_new, y_cv))\n",
    "\n",
    "score = model.evaluate(X_test_new, y_test, batch_size=batchsize)\n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "final_output = final_output.append({\"Model\": 1,\n",
    "                                    \"Architecture\": 'Embedding-LSTM-Sigmoid', \n",
    "                                    \"TRAIN_LOSS\": '{:.5f}'.format(m_hist.history[\"loss\"][n_epochs-1]),\n",
    "                                    \"TEST_LOSS\": '{:.5f}'.format(score[0]),\n",
    "                                    \"TRAIN_ACC\": '{:.5f}'.format(m_hist.history[\"acc\"][n_epochs-1]),\n",
    "                                    \"TEST_ACC\": '{:.5f}'.format(score[1])}, ignore_index=True)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,n_epochs+1))\n",
    "\n",
    "vy = m_hist.history['val_loss']\n",
    "ty = m_hist.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with 2 layers and 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1000, 100)         53200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 293,701\n",
      "Trainable params: 293,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(5000, embedding_vecor_length, input_length=max_review_length))\n",
    "model1.add(LSTM(100, return_sequences=True))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "n_epochs = 10\n",
    "batchsize = 700\n",
    "\n",
    "final_output = pd.DataFrame(columns=[\"Model\", \"Architecture\",\n",
    "                                     \"TRAIN_LOSS\", \"TEST_LOSS\", \"TRAIN_ACC\", \"TEST_ACC\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56614 samples, validate on 14154 samples\n",
      "Epoch 1/10\n",
      "56614/56614 [==============================] - ETA: 2:04:19 - loss: 0.1216 - acc: 0.95 - ETA: 1:58:49 - loss: 0.1265 - acc: 0.95 - ETA: 1:56:23 - loss: 0.1276 - acc: 0.94 - ETA: 1:54:28 - loss: 0.1220 - acc: 0.95 - ETA: 1:52:17 - loss: 0.1234 - acc: 0.95 - ETA: 1:51:58 - loss: 0.1253 - acc: 0.95 - ETA: 1:50:46 - loss: 0.1243 - acc: 0.95 - ETA: 1:50:47 - loss: 0.1217 - acc: 0.95 - ETA: 1:51:08 - loss: 0.1201 - acc: 0.95 - ETA: 1:49:24 - loss: 0.1231 - acc: 0.95 - ETA: 1:47:27 - loss: 0.1224 - acc: 0.95 - ETA: 1:46:28 - loss: 0.1230 - acc: 0.95 - ETA: 1:46:30 - loss: 0.1221 - acc: 0.95 - ETA: 1:44:39 - loss: 0.1235 - acc: 0.95 - ETA: 1:43:21 - loss: 0.1249 - acc: 0.95 - ETA: 1:42:05 - loss: 0.1246 - acc: 0.95 - ETA: 1:40:41 - loss: 0.1261 - acc: 0.95 - ETA: 1:39:11 - loss: 0.1258 - acc: 0.95 - ETA: 1:37:25 - loss: 0.1270 - acc: 0.95 - ETA: 1:35:47 - loss: 0.1272 - acc: 0.95 - ETA: 1:34:09 - loss: 0.1266 - acc: 0.95 - ETA: 1:32:40 - loss: 0.1277 - acc: 0.95 - ETA: 1:31:09 - loss: 0.1290 - acc: 0.94 - ETA: 1:29:41 - loss: 0.1279 - acc: 0.95 - ETA: 1:28:15 - loss: 0.1263 - acc: 0.95 - ETA: 1:26:42 - loss: 0.1260 - acc: 0.95 - ETA: 1:25:16 - loss: 0.1264 - acc: 0.95 - ETA: 1:23:45 - loss: 0.1267 - acc: 0.95 - ETA: 1:46:43 - loss: 0.1263 - acc: 0.95 - ETA: 1:55:30 - loss: 0.1282 - acc: 0.95 - ETA: 1:52:15 - loss: 0.1285 - acc: 0.95 - ETA: 1:49:08 - loss: 0.1280 - acc: 0.95 - ETA: 1:46:22 - loss: 0.1285 - acc: 0.95 - ETA: 1:43:43 - loss: 0.1287 - acc: 0.95 - ETA: 1:40:46 - loss: 0.1280 - acc: 0.95 - ETA: 1:38:15 - loss: 0.1282 - acc: 0.95 - ETA: 1:35:31 - loss: 0.1283 - acc: 0.95 - ETA: 1:32:59 - loss: 0.1288 - acc: 0.95 - ETA: 1:30:26 - loss: 0.1294 - acc: 0.94 - ETA: 1:27:56 - loss: 0.1300 - acc: 0.94 - ETA: 1:25:23 - loss: 0.1302 - acc: 0.94 - ETA: 1:22:59 - loss: 0.1309 - acc: 0.94 - ETA: 1:20:38 - loss: 0.1315 - acc: 0.94 - ETA: 1:18:15 - loss: 0.1319 - acc: 0.94 - ETA: 1:15:46 - loss: 0.1315 - acc: 0.94 - ETA: 1:13:26 - loss: 0.1318 - acc: 0.94 - ETA: 1:11:06 - loss: 0.1321 - acc: 0.94 - ETA: 1:08:46 - loss: 0.1317 - acc: 0.94 - ETA: 1:06:29 - loss: 0.1322 - acc: 0.94 - ETA: 1:04:15 - loss: 0.1326 - acc: 0.94 - ETA: 1:02:05 - loss: 0.1331 - acc: 0.94 - ETA: 59:54 - loss: 0.1329 - acc: 0.9480 - ETA: 57:47 - loss: 0.1329 - acc: 0.94 - ETA: 55:36 - loss: 0.1326 - acc: 0.94 - ETA: 53:27 - loss: 0.1327 - acc: 0.94 - ETA: 51:13 - loss: 0.1329 - acc: 0.94 - ETA: 49:07 - loss: 0.1324 - acc: 0.94 - ETA: 47:05 - loss: 0.1325 - acc: 0.94 - ETA: 45:03 - loss: 0.1323 - acc: 0.94 - ETA: 42:58 - loss: 0.1321 - acc: 0.94 - ETA: 40:57 - loss: 0.1322 - acc: 0.94 - ETA: 38:55 - loss: 0.1320 - acc: 0.94 - ETA: 36:54 - loss: 0.1319 - acc: 0.94 - ETA: 34:49 - loss: 0.1318 - acc: 0.94 - ETA: 32:45 - loss: 0.1316 - acc: 0.94 - ETA: 30:43 - loss: 0.1323 - acc: 0.94 - ETA: 28:41 - loss: 0.1326 - acc: 0.94 - ETA: 26:37 - loss: 0.1331 - acc: 0.94 - ETA: 24:33 - loss: 0.1334 - acc: 0.94 - ETA: 22:29 - loss: 0.1336 - acc: 0.94 - ETA: 20:24 - loss: 0.1339 - acc: 0.94 - ETA: 18:20 - loss: 0.1340 - acc: 0.94 - ETA: 16:17 - loss: 0.1341 - acc: 0.94 - ETA: 14:12 - loss: 0.1338 - acc: 0.94 - ETA: 12:07 - loss: 0.1344 - acc: 0.94 - ETA: 10:03 - loss: 0.1344 - acc: 0.94 - ETA: 8:00 - loss: 0.1350 - acc: 0.9468 - ETA: 5:56 - loss: 0.1350 - acc: 0.946 - ETA: 3:52 - loss: 0.1351 - acc: 0.946 - ETA: 1:48 - loss: 0.1351 - acc: 0.946 - 10332s 182ms/step - loss: 0.1356 - acc: 0.9464 - val_loss: 0.1958 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "56614/56614 [==============================] - ETA: 2:51:50 - loss: 0.1211 - acc: 0.96 - ETA: 2:49:58 - loss: 0.1218 - acc: 0.95 - ETA: 2:46:21 - loss: 0.1363 - acc: 0.94 - ETA: 2:40:46 - loss: 0.1333 - acc: 0.94 - ETA: 2:34:26 - loss: 0.1299 - acc: 0.95 - ETA: 2:29:29 - loss: 0.1300 - acc: 0.94 - ETA: 2:26:03 - loss: 0.1328 - acc: 0.94 - ETA: 2:24:16 - loss: 0.1300 - acc: 0.94 - ETA: 2:20:18 - loss: 0.1306 - acc: 0.94 - ETA: 2:16:31 - loss: 0.1303 - acc: 0.94 - ETA: 2:13:11 - loss: 0.1294 - acc: 0.95 - ETA: 2:10:23 - loss: 0.1284 - acc: 0.95 - ETA: 2:07:33 - loss: 0.1269 - acc: 0.95 - ETA: 2:04:45 - loss: 0.1272 - acc: 0.95 - ETA: 2:02:15 - loss: 0.1280 - acc: 0.95 - ETA: 1:59:43 - loss: 0.1279 - acc: 0.95 - ETA: 1:57:22 - loss: 0.1273 - acc: 0.95 - ETA: 1:55:08 - loss: 0.1284 - acc: 0.95 - ETA: 1:52:53 - loss: 0.1278 - acc: 0.95 - ETA: 1:50:44 - loss: 0.1272 - acc: 0.95 - ETA: 1:48:36 - loss: 0.1286 - acc: 0.95 - ETA: 1:46:34 - loss: 0.1276 - acc: 0.95 - ETA: 1:44:38 - loss: 0.1280 - acc: 0.95 - ETA: 1:42:35 - loss: 0.1275 - acc: 0.95 - ETA: 1:40:35 - loss: 0.1287 - acc: 0.95 - ETA: 1:38:33 - loss: 0.1297 - acc: 0.95 - ETA: 1:36:36 - loss: 0.1295 - acc: 0.95 - ETA: 1:34:41 - loss: 0.1301 - acc: 0.95 - ETA: 1:32:49 - loss: 0.1312 - acc: 0.94 - ETA: 1:30:57 - loss: 0.1313 - acc: 0.94 - ETA: 1:29:05 - loss: 0.1312 - acc: 0.94 - ETA: 1:27:12 - loss: 0.1309 - acc: 0.94 - ETA: 1:25:21 - loss: 0.1309 - acc: 0.94 - ETA: 1:23:32 - loss: 0.1313 - acc: 0.94 - ETA: 1:21:38 - loss: 0.1321 - acc: 0.94 - ETA: 1:19:46 - loss: 0.1331 - acc: 0.94 - ETA: 1:18:01 - loss: 0.1333 - acc: 0.94 - ETA: 1:16:11 - loss: 0.1334 - acc: 0.94 - ETA: 1:14:24 - loss: 0.1332 - acc: 0.94 - ETA: 1:12:34 - loss: 0.1336 - acc: 0.94 - ETA: 1:10:46 - loss: 0.1341 - acc: 0.94 - ETA: 1:08:58 - loss: 0.1350 - acc: 0.94 - ETA: 1:07:11 - loss: 0.1346 - acc: 0.94 - ETA: 1:05:22 - loss: 0.1349 - acc: 0.94 - ETA: 1:03:35 - loss: 0.1351 - acc: 0.94 - ETA: 1:01:47 - loss: 0.1356 - acc: 0.94 - ETA: 1:00:01 - loss: 0.1355 - acc: 0.94 - ETA: 58:12 - loss: 0.1358 - acc: 0.9469 - ETA: 56:27 - loss: 0.1359 - acc: 0.94 - ETA: 54:41 - loss: 0.1362 - acc: 0.94 - ETA: 52:53 - loss: 0.1360 - acc: 0.94 - ETA: 51:06 - loss: 0.1360 - acc: 0.94 - ETA: 49:19 - loss: 0.1359 - acc: 0.94 - ETA: 47:32 - loss: 0.1357 - acc: 0.94 - ETA: 45:44 - loss: 0.1353 - acc: 0.94 - ETA: 43:56 - loss: 0.1357 - acc: 0.94 - ETA: 42:10 - loss: 0.1353 - acc: 0.94 - ETA: 40:24 - loss: 0.1353 - acc: 0.94 - ETA: 38:38 - loss: 0.1348 - acc: 0.94 - ETA: 36:51 - loss: 0.1347 - acc: 0.94 - ETA: 35:06 - loss: 0.1354 - acc: 0.94 - ETA: 33:20 - loss: 0.1352 - acc: 0.94 - ETA: 31:33 - loss: 0.1354 - acc: 0.94 - ETA: 29:47 - loss: 0.1354 - acc: 0.94 - ETA: 28:02 - loss: 0.1360 - acc: 0.94 - ETA: 26:17 - loss: 0.1359 - acc: 0.94 - ETA: 24:30 - loss: 0.1356 - acc: 0.94 - ETA: 22:44 - loss: 0.1353 - acc: 0.94 - ETA: 20:58 - loss: 0.1353 - acc: 0.94 - ETA: 19:12 - loss: 0.1353 - acc: 0.94 - ETA: 17:26 - loss: 0.1354 - acc: 0.94 - ETA: 15:40 - loss: 0.1351 - acc: 0.94 - ETA: 13:54 - loss: 0.1353 - acc: 0.94 - ETA: 12:08 - loss: 0.1351 - acc: 0.94 - ETA: 10:22 - loss: 0.1353 - acc: 0.94 - ETA: 8:36 - loss: 0.1348 - acc: 0.9471 - ETA: 6:50 - loss: 0.1350 - acc: 0.947 - ETA: 5:04 - loss: 0.1350 - acc: 0.947 - ETA: 3:18 - loss: 0.1349 - acc: 0.947 - ETA: 1:32 - loss: 0.1348 - acc: 0.947 - 8817s 156ms/step - loss: 0.1351 - acc: 0.9470 - val_loss: 0.2050 - val_acc: 0.9201\n",
      "Epoch 3/10\n",
      "56614/56614 [==============================] - ETA: 2:16:58 - loss: 0.1138 - acc: 0.95 - ETA: 2:16:57 - loss: 0.1164 - acc: 0.95 - ETA: 2:15:14 - loss: 0.1096 - acc: 0.95 - ETA: 2:13:53 - loss: 0.1125 - acc: 0.95 - ETA: 2:12:17 - loss: 0.1105 - acc: 0.95 - ETA: 2:10:44 - loss: 0.1144 - acc: 0.95 - ETA: 2:09:12 - loss: 0.1117 - acc: 0.95 - ETA: 2:07:19 - loss: 0.1121 - acc: 0.95 - ETA: 2:05:25 - loss: 0.1135 - acc: 0.95 - ETA: 2:03:39 - loss: 0.1123 - acc: 0.95 - ETA: 2:02:24 - loss: 0.1124 - acc: 0.95 - ETA: 2:00:38 - loss: 0.1111 - acc: 0.95 - ETA: 1:58:54 - loss: 0.1135 - acc: 0.95 - ETA: 1:57:13 - loss: 0.1155 - acc: 0.95 - ETA: 1:55:20 - loss: 0.1139 - acc: 0.95 - ETA: 1:53:38 - loss: 0.1139 - acc: 0.95 - ETA: 1:51:50 - loss: 0.1135 - acc: 0.95 - ETA: 1:50:02 - loss: 0.1144 - acc: 0.95 - ETA: 1:48:19 - loss: 0.1145 - acc: 0.95 - ETA: 1:46:34 - loss: 0.1153 - acc: 0.95 - ETA: 1:44:45 - loss: 0.1150 - acc: 0.95 - ETA: 1:42:58 - loss: 0.1149 - acc: 0.95 - ETA: 1:41:11 - loss: 0.1150 - acc: 0.95 - ETA: 1:39:36 - loss: 0.1161 - acc: 0.95 - ETA: 1:37:50 - loss: 0.1154 - acc: 0.95 - ETA: 1:36:04 - loss: 0.1154 - acc: 0.95 - ETA: 1:34:27 - loss: 0.1149 - acc: 0.95 - ETA: 1:32:42 - loss: 0.1152 - acc: 0.95 - ETA: 1:30:54 - loss: 0.1160 - acc: 0.95 - ETA: 1:29:09 - loss: 0.1168 - acc: 0.95 - ETA: 1:27:25 - loss: 0.1169 - acc: 0.95 - ETA: 1:25:40 - loss: 0.1173 - acc: 0.95 - ETA: 1:23:57 - loss: 0.1175 - acc: 0.95 - ETA: 1:22:13 - loss: 0.1170 - acc: 0.95 - ETA: 1:20:29 - loss: 0.1170 - acc: 0.95 - ETA: 1:18:41 - loss: 0.1173 - acc: 0.95 - ETA: 1:16:53 - loss: 0.1175 - acc: 0.95 - ETA: 1:15:10 - loss: 0.1179 - acc: 0.95 - ETA: 1:13:24 - loss: 0.1183 - acc: 0.95 - ETA: 1:11:37 - loss: 0.1189 - acc: 0.95 - ETA: 1:09:52 - loss: 0.1187 - acc: 0.95 - ETA: 1:08:12 - loss: 0.1192 - acc: 0.95 - ETA: 1:06:26 - loss: 0.1200 - acc: 0.95 - ETA: 1:04:39 - loss: 0.1202 - acc: 0.95 - ETA: 1:02:55 - loss: 0.1211 - acc: 0.95 - ETA: 1:01:10 - loss: 0.1212 - acc: 0.95 - ETA: 59:24 - loss: 0.1215 - acc: 0.9533 - ETA: 57:39 - loss: 0.1214 - acc: 0.95 - ETA: 55:53 - loss: 0.1211 - acc: 0.95 - ETA: 54:06 - loss: 0.1215 - acc: 0.95 - ETA: 52:23 - loss: 0.1220 - acc: 0.95 - ETA: 50:39 - loss: 0.1225 - acc: 0.95 - ETA: 48:55 - loss: 0.1231 - acc: 0.95 - ETA: 47:12 - loss: 0.1234 - acc: 0.95 - ETA: 45:27 - loss: 0.1237 - acc: 0.95 - ETA: 43:42 - loss: 0.1237 - acc: 0.95 - ETA: 41:58 - loss: 0.1237 - acc: 0.95 - ETA: 40:12 - loss: 0.1244 - acc: 0.95 - ETA: 38:27 - loss: 0.1247 - acc: 0.95 - ETA: 36:41 - loss: 0.1246 - acc: 0.95 - ETA: 34:56 - loss: 0.1251 - acc: 0.95 - ETA: 33:11 - loss: 0.1251 - acc: 0.95 - ETA: 31:26 - loss: 0.1255 - acc: 0.95 - ETA: 29:41 - loss: 0.1257 - acc: 0.95 - ETA: 27:56 - loss: 0.1255 - acc: 0.95 - ETA: 26:10 - loss: 0.1253 - acc: 0.95 - ETA: 24:24 - loss: 0.1258 - acc: 0.95 - ETA: 22:38 - loss: 0.1261 - acc: 0.95 - ETA: 20:53 - loss: 0.1261 - acc: 0.95 - ETA: 19:07 - loss: 0.1263 - acc: 0.95 - ETA: 17:21 - loss: 0.1266 - acc: 0.95 - ETA: 15:36 - loss: 0.1267 - acc: 0.95 - ETA: 13:50 - loss: 0.1267 - acc: 0.95 - ETA: 12:05 - loss: 0.1266 - acc: 0.95 - ETA: 10:19 - loss: 0.1267 - acc: 0.95 - ETA: 8:34 - loss: 0.1266 - acc: 0.9514 - ETA: 6:49 - loss: 0.1263 - acc: 0.951 - ETA: 5:03 - loss: 0.1263 - acc: 0.951 - ETA: 3:18 - loss: 0.1269 - acc: 0.951 - ETA: 1:32 - loss: 0.1269 - acc: 0.951 - 8800s 155ms/step - loss: 0.1270 - acc: 0.9510 - val_loss: 0.2021 - val_acc: 0.9153\n",
      "Epoch 4/10\n",
      "56614/56614 [==============================] - ETA: 2:21:10 - loss: 0.1338 - acc: 0.95 - ETA: 2:21:10 - loss: 0.1311 - acc: 0.95 - ETA: 2:19:19 - loss: 0.1265 - acc: 0.95 - ETA: 2:17:41 - loss: 0.1210 - acc: 0.95 - ETA: 2:15:34 - loss: 0.1157 - acc: 0.95 - ETA: 2:13:43 - loss: 0.1165 - acc: 0.95 - ETA: 2:11:46 - loss: 0.1135 - acc: 0.95 - ETA: 2:09:43 - loss: 0.1123 - acc: 0.95 - ETA: 2:07:48 - loss: 0.1129 - acc: 0.95 - ETA: 2:06:06 - loss: 0.1131 - acc: 0.95 - ETA: 2:04:17 - loss: 0.1148 - acc: 0.95 - ETA: 2:02:36 - loss: 0.1160 - acc: 0.95 - ETA: 2:00:34 - loss: 0.1171 - acc: 0.95 - ETA: 1:59:12 - loss: 0.1167 - acc: 0.95 - ETA: 1:57:29 - loss: 0.1199 - acc: 0.95 - ETA: 1:55:36 - loss: 0.1185 - acc: 0.95 - ETA: 1:53:53 - loss: 0.1197 - acc: 0.95 - ETA: 1:52:02 - loss: 0.1193 - acc: 0.95 - ETA: 1:50:10 - loss: 0.1192 - acc: 0.95 - ETA: 1:48:28 - loss: 0.1195 - acc: 0.95 - ETA: 1:46:32 - loss: 0.1185 - acc: 0.95 - ETA: 1:44:44 - loss: 0.1182 - acc: 0.95 - ETA: 1:43:01 - loss: 0.1193 - acc: 0.95 - ETA: 1:41:10 - loss: 0.1183 - acc: 0.95 - ETA: 1:39:24 - loss: 0.1182 - acc: 0.95 - ETA: 1:37:34 - loss: 0.1174 - acc: 0.95 - ETA: 1:35:44 - loss: 0.1168 - acc: 0.95 - ETA: 1:34:01 - loss: 0.1163 - acc: 0.95 - ETA: 1:32:12 - loss: 0.1168 - acc: 0.95 - ETA: 1:30:22 - loss: 0.1163 - acc: 0.95 - ETA: 1:28:34 - loss: 0.1178 - acc: 0.95 - ETA: 1:26:45 - loss: 0.1179 - acc: 0.95 - ETA: 1:25:00 - loss: 0.1178 - acc: 0.95 - ETA: 1:23:12 - loss: 0.1180 - acc: 0.95 - ETA: 1:21:25 - loss: 0.1186 - acc: 0.95 - ETA: 1:19:43 - loss: 0.1186 - acc: 0.95 - ETA: 1:17:56 - loss: 0.1190 - acc: 0.95 - ETA: 1:16:09 - loss: 0.1190 - acc: 0.95 - ETA: 1:14:24 - loss: 0.1194 - acc: 0.95 - ETA: 1:12:39 - loss: 0.1194 - acc: 0.95 - ETA: 1:10:51 - loss: 0.1196 - acc: 0.95 - ETA: 1:09:07 - loss: 0.1202 - acc: 0.95 - ETA: 1:07:22 - loss: 0.1198 - acc: 0.95 - ETA: 1:05:37 - loss: 0.1200 - acc: 0.95 - ETA: 1:03:51 - loss: 0.1205 - acc: 0.95 - ETA: 1:02:06 - loss: 0.1207 - acc: 0.95 - ETA: 1:00:20 - loss: 0.1207 - acc: 0.95 - ETA: 58:32 - loss: 0.1208 - acc: 0.9535 - ETA: 56:45 - loss: 0.1208 - acc: 0.95 - ETA: 54:59 - loss: 0.1211 - acc: 0.95 - ETA: 53:12 - loss: 0.1212 - acc: 0.95 - ETA: 51:25 - loss: 0.1214 - acc: 0.95 - ETA: 49:39 - loss: 0.1214 - acc: 0.95 - ETA: 47:54 - loss: 0.1214 - acc: 0.95 - ETA: 46:06 - loss: 0.1213 - acc: 0.95 - ETA: 44:20 - loss: 0.1212 - acc: 0.95 - ETA: 42:33 - loss: 0.1211 - acc: 0.95 - ETA: 40:46 - loss: 0.1213 - acc: 0.95 - ETA: 38:59 - loss: 0.1213 - acc: 0.95 - ETA: 37:13 - loss: 0.1217 - acc: 0.95 - ETA: 35:26 - loss: 0.1216 - acc: 0.95 - ETA: 33:38 - loss: 0.1217 - acc: 0.95 - ETA: 31:52 - loss: 0.1218 - acc: 0.95 - ETA: 30:05 - loss: 0.1220 - acc: 0.95 - ETA: 28:18 - loss: 0.1218 - acc: 0.95 - ETA: 26:31 - loss: 0.1218 - acc: 0.95 - ETA: 24:45 - loss: 0.1220 - acc: 0.95 - ETA: 22:57 - loss: 0.1221 - acc: 0.95 - ETA: 21:10 - loss: 0.1221 - acc: 0.95 - ETA: 19:23 - loss: 0.1220 - acc: 0.95 - ETA: 17:36 - loss: 0.1220 - acc: 0.95 - ETA: 15:49 - loss: 0.1221 - acc: 0.95 - ETA: 14:02 - loss: 0.1223 - acc: 0.95 - ETA: 12:15 - loss: 0.1225 - acc: 0.95 - ETA: 10:28 - loss: 0.1224 - acc: 0.95 - ETA: 8:41 - loss: 0.1223 - acc: 0.9526 - ETA: 6:54 - loss: 0.1222 - acc: 0.952 - ETA: 5:07 - loss: 0.1221 - acc: 0.952 - ETA: 3:20 - loss: 0.1221 - acc: 0.952 - ETA: 1:33 - loss: 0.1220 - acc: 0.952 - 8922s 158ms/step - loss: 0.1220 - acc: 0.9527 - val_loss: 0.2078 - val_acc: 0.9182\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56614/56614 [==============================] - ETA: 2:19:50 - loss: 0.1181 - acc: 0.96 - ETA: 2:17:44 - loss: 0.1171 - acc: 0.95 - ETA: 2:15:56 - loss: 0.1218 - acc: 0.95 - ETA: 2:14:16 - loss: 0.1169 - acc: 0.95 - ETA: 2:12:22 - loss: 0.1135 - acc: 0.95 - ETA: 2:10:34 - loss: 0.1151 - acc: 0.95 - ETA: 2:09:04 - loss: 0.1132 - acc: 0.95 - ETA: 2:07:55 - loss: 0.1132 - acc: 0.95 - ETA: 2:06:14 - loss: 0.1144 - acc: 0.95 - ETA: 2:04:50 - loss: 0.1158 - acc: 0.95 - ETA: 2:03:15 - loss: 0.1164 - acc: 0.95 - ETA: 2:01:19 - loss: 0.1157 - acc: 0.95 - ETA: 1:59:36 - loss: 0.1173 - acc: 0.95 - ETA: 1:57:43 - loss: 0.1164 - acc: 0.95 - ETA: 1:55:58 - loss: 0.1159 - acc: 0.95 - ETA: 1:54:08 - loss: 0.1161 - acc: 0.95 - ETA: 1:52:18 - loss: 0.1148 - acc: 0.95 - ETA: 1:50:37 - loss: 0.1145 - acc: 0.95 - ETA: 1:48:45 - loss: 0.1135 - acc: 0.95 - ETA: 1:46:57 - loss: 0.1131 - acc: 0.95 - ETA: 1:45:12 - loss: 0.1143 - acc: 0.95 - ETA: 1:43:23 - loss: 0.1137 - acc: 0.95 - ETA: 1:41:35 - loss: 0.1142 - acc: 0.95 - ETA: 1:39:48 - loss: 0.1137 - acc: 0.95 - ETA: 1:38:02 - loss: 0.1131 - acc: 0.95 - ETA: 1:36:17 - loss: 0.1126 - acc: 0.95 - ETA: 1:34:30 - loss: 0.1132 - acc: 0.95 - ETA: 1:32:43 - loss: 0.1136 - acc: 0.95 - ETA: 1:30:58 - loss: 0.1137 - acc: 0.95 - ETA: 1:29:13 - loss: 0.1135 - acc: 0.95 - ETA: 1:27:34 - loss: 0.1137 - acc: 0.95 - ETA: 1:25:46 - loss: 0.1143 - acc: 0.95 - ETA: 1:23:59 - loss: 0.1152 - acc: 0.95 - ETA: 1:22:14 - loss: 0.1153 - acc: 0.95 - ETA: 1:20:29 - loss: 0.1155 - acc: 0.95 - ETA: 1:18:46 - loss: 0.1162 - acc: 0.95 - ETA: 1:17:00 - loss: 0.1166 - acc: 0.95 - ETA: 1:15:19 - loss: 0.1162 - acc: 0.95 - ETA: 1:13:33 - loss: 0.1166 - acc: 0.95 - ETA: 1:11:46 - loss: 0.1165 - acc: 0.95 - ETA: 1:10:01 - loss: 0.1178 - acc: 0.95 - ETA: 1:08:15 - loss: 0.1180 - acc: 0.95 - ETA: 1:06:30 - loss: 0.1175 - acc: 0.95 - ETA: 1:04:59 - loss: 0.1172 - acc: 0.95 - ETA: 1:03:35 - loss: 0.1182 - acc: 0.95 - ETA: 1:02:09 - loss: 0.1181 - acc: 0.95 - ETA: 1:00:46 - loss: 0.1179 - acc: 0.95 - ETA: 59:12 - loss: 0.1179 - acc: 0.9532 - ETA: 57:32 - loss: 0.1176 - acc: 0.95 - ETA: 55:56 - loss: 0.1177 - acc: 0.95 - ETA: 54:13 - loss: 0.1180 - acc: 0.95 - ETA: 52:42 - loss: 0.1184 - acc: 0.95 - ETA: 51:11 - loss: 0.1183 - acc: 0.95 - ETA: 49:32 - loss: 0.1185 - acc: 0.95 - ETA: 47:51 - loss: 0.1185 - acc: 0.95 - ETA: 46:05 - loss: 0.1182 - acc: 0.95 - ETA: 44:18 - loss: 0.1186 - acc: 0.95 - ETA: 42:38 - loss: 0.1189 - acc: 0.95 - ETA: 40:49 - loss: 0.1189 - acc: 0.95 - ETA: 39:00 - loss: 0.1185 - acc: 0.95 - ETA: 37:11 - loss: 0.1190 - acc: 0.95 - ETA: 35:24 - loss: 0.1191 - acc: 0.95 - ETA: 33:37 - loss: 0.1192 - acc: 0.95 - ETA: 31:47 - loss: 0.1193 - acc: 0.95 - ETA: 29:56 - loss: 0.1194 - acc: 0.95 - ETA: 28:03 - loss: 0.1196 - acc: 0.95 - ETA: 26:09 - loss: 0.1196 - acc: 0.95 - ETA: 24:17 - loss: 0.1194 - acc: 0.95 - ETA: 22:23 - loss: 0.1194 - acc: 0.95 - ETA: 20:30 - loss: 0.1194 - acc: 0.95 - ETA: 18:38 - loss: 0.1194 - acc: 0.95 - ETA: 16:46 - loss: 0.1194 - acc: 0.95 - ETA: 14:53 - loss: 0.1196 - acc: 0.95 - ETA: 13:00 - loss: 0.1204 - acc: 0.95 - ETA: 11:07 - loss: 0.1204 - acc: 0.95 - ETA: 9:14 - loss: 0.1201 - acc: 0.9523 - ETA: 7:21 - loss: 0.1205 - acc: 0.952 - ETA: 5:27 - loss: 0.1206 - acc: 0.952 - ETA: 3:34 - loss: 0.1205 - acc: 0.952 - ETA: 1:40 - loss: 0.1202 - acc: 0.952 - 9555s 169ms/step - loss: 0.1201 - acc: 0.9526 - val_loss: 0.2177 - val_acc: 0.9179\n",
      "Epoch 6/10\n",
      "56614/56614 [==============================] - ETA: 2:51:32 - loss: 0.1053 - acc: 0.96 - ETA: 2:46:19 - loss: 0.0969 - acc: 0.96 - ETA: 2:42:54 - loss: 0.1072 - acc: 0.96 - ETA: 2:39:35 - loss: 0.1036 - acc: 0.96 - ETA: 2:36:01 - loss: 0.1035 - acc: 0.96 - ETA: 2:32:24 - loss: 0.1038 - acc: 0.96 - ETA: 2:29:05 - loss: 0.1046 - acc: 0.96 - ETA: 2:26:57 - loss: 0.1057 - acc: 0.96 - ETA: 2:26:18 - loss: 0.1042 - acc: 0.96 - ETA: 2:25:11 - loss: 0.1046 - acc: 0.96 - ETA: 2:23:18 - loss: 0.1039 - acc: 0.96 - ETA: 2:21:20 - loss: 0.1048 - acc: 0.96 - ETA: 2:19:13 - loss: 0.1056 - acc: 0.96 - ETA: 2:16:51 - loss: 0.1051 - acc: 0.96 - ETA: 2:15:02 - loss: 0.1052 - acc: 0.96 - ETA: 2:12:44 - loss: 0.1053 - acc: 0.96 - ETA: 2:10:35 - loss: 0.1060 - acc: 0.96 - ETA: 2:08:21 - loss: 0.1063 - acc: 0.96 - ETA: 2:06:46 - loss: 0.1064 - acc: 0.96 - ETA: 2:04:48 - loss: 0.1068 - acc: 0.96 - ETA: 2:02:49 - loss: 0.1081 - acc: 0.96 - ETA: 2:00:32 - loss: 0.1094 - acc: 0.96 - ETA: 1:58:26 - loss: 0.1087 - acc: 0.96 - ETA: 1:56:45 - loss: 0.1093 - acc: 0.96 - ETA: 1:54:43 - loss: 0.1095 - acc: 0.96 - ETA: 1:52:20 - loss: 0.1107 - acc: 0.95 - ETA: 1:50:20 - loss: 0.1114 - acc: 0.95 - ETA: 1:48:10 - loss: 0.1116 - acc: 0.95 - ETA: 1:46:11 - loss: 0.1118 - acc: 0.95 - ETA: 1:44:12 - loss: 0.1110 - acc: 0.95 - ETA: 1:42:03 - loss: 0.1104 - acc: 0.95 - ETA: 1:39:53 - loss: 0.1099 - acc: 0.96 - ETA: 1:37:52 - loss: 0.1102 - acc: 0.95 - ETA: 1:35:47 - loss: 0.1100 - acc: 0.95 - ETA: 1:33:38 - loss: 0.1096 - acc: 0.95 - ETA: 1:31:36 - loss: 0.1090 - acc: 0.95 - ETA: 1:29:28 - loss: 0.1089 - acc: 0.96 - ETA: 1:27:32 - loss: 0.1094 - acc: 0.95 - ETA: 1:25:33 - loss: 0.1103 - acc: 0.95 - ETA: 1:23:31 - loss: 0.1104 - acc: 0.95 - ETA: 1:21:29 - loss: 0.1103 - acc: 0.95 - ETA: 1:19:26 - loss: 0.1098 - acc: 0.95 - ETA: 1:17:20 - loss: 0.1096 - acc: 0.95 - ETA: 1:15:17 - loss: 0.1105 - acc: 0.95 - ETA: 1:13:07 - loss: 0.1107 - acc: 0.95 - ETA: 1:11:07 - loss: 0.1108 - acc: 0.95 - ETA: 1:09:09 - loss: 0.1109 - acc: 0.95 - ETA: 1:07:08 - loss: 0.1110 - acc: 0.95 - ETA: 1:05:13 - loss: 0.1105 - acc: 0.95 - ETA: 1:03:11 - loss: 0.1110 - acc: 0.95 - ETA: 1:01:03 - loss: 0.1112 - acc: 0.95 - ETA: 59:00 - loss: 0.1106 - acc: 0.9584 - ETA: 56:53 - loss: 0.1108 - acc: 0.95 - ETA: 54:48 - loss: 0.1109 - acc: 0.95 - ETA: 52:41 - loss: 0.1106 - acc: 0.95 - ETA: 50:34 - loss: 0.1108 - acc: 0.95 - ETA: 48:29 - loss: 0.1112 - acc: 0.95 - ETA: 46:28 - loss: 0.1109 - acc: 0.95 - ETA: 44:26 - loss: 0.1110 - acc: 0.95 - ETA: 42:27 - loss: 0.1108 - acc: 0.95 - ETA: 40:24 - loss: 0.1111 - acc: 0.95 - ETA: 38:20 - loss: 0.1116 - acc: 0.95 - ETA: 36:22 - loss: 0.1112 - acc: 0.95 - ETA: 34:19 - loss: 0.1111 - acc: 0.95 - ETA: 32:18 - loss: 0.1112 - acc: 0.95 - ETA: 30:22 - loss: 0.1111 - acc: 0.95 - ETA: 28:25 - loss: 0.1108 - acc: 0.95 - ETA: 26:27 - loss: 0.1107 - acc: 0.95 - ETA: 24:26 - loss: 0.1107 - acc: 0.95 - ETA: 22:26 - loss: 0.1105 - acc: 0.95 - ETA: 20:25 - loss: 0.1105 - acc: 0.95 - ETA: 18:23 - loss: 0.1109 - acc: 0.95 - ETA: 16:19 - loss: 0.1109 - acc: 0.95 - ETA: 14:14 - loss: 0.1110 - acc: 0.95 - ETA: 12:08 - loss: 0.1110 - acc: 0.95 - ETA: 10:03 - loss: 0.1112 - acc: 0.95 - ETA: 7:59 - loss: 0.1111 - acc: 0.9579 - ETA: 5:55 - loss: 0.1110 - acc: 0.957 - ETA: 3:51 - loss: 0.1109 - acc: 0.957 - ETA: 1:47 - loss: 0.1111 - acc: 0.957 - 10216s 180ms/step - loss: 0.1111 - acc: 0.9578 - val_loss: 0.2201 - val_acc: 0.9164\n",
      "Epoch 7/10\n",
      "56614/56614 [==============================] - ETA: 2:24:46 - loss: 0.0846 - acc: 0.96 - ETA: 2:21:56 - loss: 0.0830 - acc: 0.96 - ETA: 2:19:33 - loss: 0.0858 - acc: 0.96 - ETA: 2:17:57 - loss: 0.0896 - acc: 0.96 - ETA: 2:16:19 - loss: 0.0916 - acc: 0.96 - ETA: 2:14:23 - loss: 0.0983 - acc: 0.96 - ETA: 2:12:57 - loss: 0.0980 - acc: 0.96 - ETA: 2:11:29 - loss: 0.0965 - acc: 0.96 - ETA: 2:09:47 - loss: 0.0963 - acc: 0.96 - ETA: 2:07:52 - loss: 0.0952 - acc: 0.96 - ETA: 2:07:40 - loss: 0.0940 - acc: 0.96 - ETA: 2:05:50 - loss: 0.0954 - acc: 0.96 - ETA: 2:04:18 - loss: 0.0955 - acc: 0.96 - ETA: 2:02:41 - loss: 0.0951 - acc: 0.96 - ETA: 2:00:54 - loss: 0.0948 - acc: 0.96 - ETA: 1:59:05 - loss: 0.0945 - acc: 0.96 - ETA: 1:57:21 - loss: 0.0955 - acc: 0.96 - ETA: 1:55:39 - loss: 0.0965 - acc: 0.96 - ETA: 1:53:32 - loss: 0.0957 - acc: 0.96 - ETA: 1:51:24 - loss: 0.0966 - acc: 0.96 - ETA: 1:49:22 - loss: 0.0962 - acc: 0.96 - ETA: 1:47:31 - loss: 0.0958 - acc: 0.96 - ETA: 1:45:33 - loss: 0.0965 - acc: 0.96 - ETA: 1:43:33 - loss: 0.0970 - acc: 0.96 - ETA: 1:41:35 - loss: 0.0975 - acc: 0.96 - ETA: 1:39:44 - loss: 0.0983 - acc: 0.96 - ETA: 1:37:58 - loss: 0.0982 - acc: 0.96 - ETA: 1:36:13 - loss: 0.0987 - acc: 0.96 - ETA: 1:34:38 - loss: 0.0998 - acc: 0.96 - ETA: 1:32:42 - loss: 0.1005 - acc: 0.96 - ETA: 1:30:52 - loss: 0.1004 - acc: 0.96 - ETA: 1:28:56 - loss: 0.1001 - acc: 0.96 - ETA: 1:27:02 - loss: 0.0998 - acc: 0.96 - ETA: 1:25:08 - loss: 0.1001 - acc: 0.96 - ETA: 1:23:13 - loss: 0.1002 - acc: 0.96 - ETA: 1:21:19 - loss: 0.1008 - acc: 0.96 - ETA: 1:19:27 - loss: 0.1006 - acc: 0.96 - ETA: 1:17:36 - loss: 0.1006 - acc: 0.96 - ETA: 1:15:47 - loss: 0.1009 - acc: 0.96 - ETA: 1:13:55 - loss: 0.1008 - acc: 0.96 - ETA: 1:12:02 - loss: 0.1011 - acc: 0.96 - ETA: 1:10:14 - loss: 0.1010 - acc: 0.96 - ETA: 1:08:24 - loss: 0.1016 - acc: 0.96 - ETA: 1:06:33 - loss: 0.1017 - acc: 0.96 - ETA: 1:04:48 - loss: 0.1017 - acc: 0.96 - ETA: 1:02:59 - loss: 0.1019 - acc: 0.96 - ETA: 1:01:10 - loss: 0.1017 - acc: 0.96 - ETA: 59:22 - loss: 0.1016 - acc: 0.9624 - ETA: 57:34 - loss: 0.1020 - acc: 0.96 - ETA: 55:46 - loss: 0.1026 - acc: 0.96 - ETA: 53:59 - loss: 0.1024 - acc: 0.96 - ETA: 52:10 - loss: 0.1021 - acc: 0.96 - ETA: 50:21 - loss: 0.1017 - acc: 0.96 - ETA: 48:33 - loss: 0.1015 - acc: 0.96 - ETA: 46:43 - loss: 0.1017 - acc: 0.96 - ETA: 44:57 - loss: 0.1016 - acc: 0.96 - ETA: 43:07 - loss: 0.1019 - acc: 0.96 - ETA: 41:19 - loss: 0.1027 - acc: 0.96 - ETA: 39:31 - loss: 0.1027 - acc: 0.96 - ETA: 37:42 - loss: 0.1030 - acc: 0.96 - ETA: 35:54 - loss: 0.1033 - acc: 0.96 - ETA: 34:06 - loss: 0.1034 - acc: 0.96 - ETA: 32:17 - loss: 0.1037 - acc: 0.96 - ETA: 30:30 - loss: 0.1037 - acc: 0.96 - ETA: 28:41 - loss: 0.1035 - acc: 0.96 - ETA: 26:53 - loss: 0.1039 - acc: 0.96 - ETA: 25:05 - loss: 0.1043 - acc: 0.96 - ETA: 23:16 - loss: 0.1042 - acc: 0.96 - ETA: 21:27 - loss: 0.1042 - acc: 0.96 - ETA: 19:39 - loss: 0.1049 - acc: 0.96 - ETA: 17:51 - loss: 0.1052 - acc: 0.96 - ETA: 16:03 - loss: 0.1054 - acc: 0.96 - ETA: 14:14 - loss: 0.1055 - acc: 0.96 - ETA: 12:26 - loss: 0.1060 - acc: 0.96 - ETA: 10:37 - loss: 0.1065 - acc: 0.96 - ETA: 8:49 - loss: 0.1067 - acc: 0.9600 - ETA: 7:00 - loss: 0.1064 - acc: 0.960 - ETA: 5:11 - loss: 0.1064 - acc: 0.960 - ETA: 3:23 - loss: 0.1063 - acc: 0.959 - ETA: 1:35 - loss: 0.1065 - acc: 0.959 - 9023s 159ms/step - loss: 0.1065 - acc: 0.9597 - val_loss: 0.2296 - val_acc: 0.9137\n",
      "Epoch 8/10\n",
      "56614/56614 [==============================] - ETA: 2:18:49 - loss: 0.0985 - acc: 0.96 - ETA: 2:16:32 - loss: 0.0957 - acc: 0.96 - ETA: 2:17:00 - loss: 0.0849 - acc: 0.97 - ETA: 2:16:47 - loss: 0.0863 - acc: 0.97 - ETA: 2:14:25 - loss: 0.0851 - acc: 0.97 - ETA: 2:12:22 - loss: 0.0884 - acc: 0.96 - ETA: 2:10:44 - loss: 0.0893 - acc: 0.96 - ETA: 2:09:23 - loss: 0.0910 - acc: 0.96 - ETA: 2:07:15 - loss: 0.0912 - acc: 0.96 - ETA: 2:05:30 - loss: 0.0920 - acc: 0.96 - ETA: 2:03:40 - loss: 0.0918 - acc: 0.96 - ETA: 2:02:07 - loss: 0.0916 - acc: 0.96 - ETA: 2:01:30 - loss: 0.0937 - acc: 0.96 - ETA: 1:59:39 - loss: 0.0932 - acc: 0.96 - ETA: 1:57:46 - loss: 0.0931 - acc: 0.96 - ETA: 1:56:20 - loss: 0.0929 - acc: 0.96 - ETA: 1:54:28 - loss: 0.0931 - acc: 0.96 - ETA: 1:52:44 - loss: 0.0926 - acc: 0.96 - ETA: 1:51:06 - loss: 0.0929 - acc: 0.96 - ETA: 1:49:32 - loss: 0.0919 - acc: 0.96 - ETA: 1:47:47 - loss: 0.0920 - acc: 0.96 - ETA: 1:45:59 - loss: 0.0918 - acc: 0.96 - ETA: 1:44:06 - loss: 0.0921 - acc: 0.96 - ETA: 1:42:12 - loss: 0.0924 - acc: 0.96 - ETA: 1:40:25 - loss: 0.0922 - acc: 0.96 - ETA: 1:38:49 - loss: 0.0920 - acc: 0.96 - ETA: 1:36:59 - loss: 0.0926 - acc: 0.96 - ETA: 1:35:12 - loss: 0.0932 - acc: 0.96 - ETA: 1:33:21 - loss: 0.0932 - acc: 0.96 - ETA: 1:31:33 - loss: 0.0936 - acc: 0.96 - ETA: 1:30:00 - loss: 0.0941 - acc: 0.96 - ETA: 1:28:25 - loss: 0.0951 - acc: 0.96 - ETA: 1:26:50 - loss: 0.0947 - acc: 0.96 - ETA: 1:25:11 - loss: 0.0949 - acc: 0.96 - ETA: 1:23:29 - loss: 0.0946 - acc: 0.96 - ETA: 1:21:47 - loss: 0.0944 - acc: 0.96 - ETA: 1:20:05 - loss: 0.0948 - acc: 0.96 - ETA: 1:18:23 - loss: 0.0947 - acc: 0.96 - ETA: 1:16:39 - loss: 0.0952 - acc: 0.96 - ETA: 1:14:54 - loss: 0.0952 - acc: 0.96 - ETA: 1:13:10 - loss: 0.0954 - acc: 0.96 - ETA: 1:11:26 - loss: 0.0959 - acc: 0.96 - ETA: 1:09:40 - loss: 0.0956 - acc: 0.96 - ETA: 1:07:57 - loss: 0.0956 - acc: 0.96 - ETA: 1:06:11 - loss: 0.0960 - acc: 0.96 - ETA: 1:04:24 - loss: 0.0960 - acc: 0.96 - ETA: 1:02:35 - loss: 0.0960 - acc: 0.96 - ETA: 1:00:46 - loss: 0.0958 - acc: 0.96 - ETA: 58:58 - loss: 0.0956 - acc: 0.9647 - ETA: 57:09 - loss: 0.0957 - acc: 0.96 - ETA: 55:20 - loss: 0.0956 - acc: 0.96 - ETA: 53:32 - loss: 0.0959 - acc: 0.96 - ETA: 51:42 - loss: 0.0960 - acc: 0.96 - ETA: 49:52 - loss: 0.0963 - acc: 0.96 - ETA: 48:03 - loss: 0.0966 - acc: 0.96 - ETA: 46:13 - loss: 0.0972 - acc: 0.96 - ETA: 44:23 - loss: 0.0969 - acc: 0.96 - ETA: 42:33 - loss: 0.0966 - acc: 0.96 - ETA: 40:42 - loss: 0.0975 - acc: 0.96 - ETA: 38:51 - loss: 0.0977 - acc: 0.96 - ETA: 37:01 - loss: 0.0978 - acc: 0.96 - ETA: 35:10 - loss: 0.0979 - acc: 0.96 - ETA: 33:19 - loss: 0.0981 - acc: 0.96 - ETA: 31:28 - loss: 0.0986 - acc: 0.96 - ETA: 29:37 - loss: 0.0987 - acc: 0.96 - ETA: 27:46 - loss: 0.0989 - acc: 0.96 - ETA: 25:55 - loss: 0.0991 - acc: 0.96 - ETA: 24:03 - loss: 0.0995 - acc: 0.96 - ETA: 22:11 - loss: 0.0995 - acc: 0.96 - ETA: 20:19 - loss: 0.0995 - acc: 0.96 - ETA: 18:28 - loss: 0.0998 - acc: 0.96 - ETA: 16:36 - loss: 0.1001 - acc: 0.96 - ETA: 14:44 - loss: 0.0998 - acc: 0.96 - ETA: 12:52 - loss: 0.1001 - acc: 0.96 - ETA: 10:59 - loss: 0.1005 - acc: 0.96 - ETA: 9:07 - loss: 0.1005 - acc: 0.9621 - ETA: 7:15 - loss: 0.1008 - acc: 0.961 - ETA: 5:23 - loss: 0.1008 - acc: 0.961 - ETA: 3:31 - loss: 0.1009 - acc: 0.961 - ETA: 1:38 - loss: 0.1012 - acc: 0.961 - 9368s 165ms/step - loss: 0.1013 - acc: 0.9616 - val_loss: 0.2338 - val_acc: 0.9162\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56614/56614 [==============================] - ETA: 2:31:38 - loss: 0.0988 - acc: 0.97 - ETA: 2:30:11 - loss: 0.0919 - acc: 0.97 - ETA: 2:28:11 - loss: 0.0888 - acc: 0.97 - ETA: 2:26:01 - loss: 0.0893 - acc: 0.97 - ETA: 2:24:09 - loss: 0.0917 - acc: 0.97 - ETA: 2:22:35 - loss: 0.0915 - acc: 0.96 - ETA: 2:20:40 - loss: 0.0964 - acc: 0.96 - ETA: 2:18:47 - loss: 0.0945 - acc: 0.96 - ETA: 2:17:01 - loss: 0.0922 - acc: 0.96 - ETA: 2:15:06 - loss: 0.0924 - acc: 0.96 - ETA: 2:13:15 - loss: 0.0915 - acc: 0.96 - ETA: 2:11:19 - loss: 0.0913 - acc: 0.96 - ETA: 2:09:32 - loss: 0.0917 - acc: 0.96 - ETA: 2:07:44 - loss: 0.0908 - acc: 0.96 - ETA: 2:06:04 - loss: 0.0908 - acc: 0.96 - ETA: 2:04:12 - loss: 0.0919 - acc: 0.96 - ETA: 2:02:22 - loss: 0.0917 - acc: 0.96 - ETA: 2:00:31 - loss: 0.0925 - acc: 0.96 - ETA: 1:58:34 - loss: 0.0918 - acc: 0.96 - ETA: 1:56:39 - loss: 0.0919 - acc: 0.96 - ETA: 1:54:44 - loss: 0.0927 - acc: 0.96 - ETA: 1:52:49 - loss: 0.0928 - acc: 0.96 - ETA: 1:50:53 - loss: 0.0934 - acc: 0.96 - ETA: 1:48:58 - loss: 0.0930 - acc: 0.96 - ETA: 1:47:01 - loss: 0.0924 - acc: 0.96 - ETA: 1:45:06 - loss: 0.0928 - acc: 0.96 - ETA: 1:43:13 - loss: 0.0932 - acc: 0.96 - ETA: 1:41:19 - loss: 0.0950 - acc: 0.96 - ETA: 1:39:22 - loss: 0.0952 - acc: 0.96 - ETA: 1:37:25 - loss: 0.0949 - acc: 0.96 - ETA: 1:35:30 - loss: 0.0939 - acc: 0.96 - ETA: 1:33:35 - loss: 0.0937 - acc: 0.96 - ETA: 1:31:39 - loss: 0.0936 - acc: 0.96 - ETA: 1:29:42 - loss: 0.0943 - acc: 0.96 - ETA: 1:27:48 - loss: 0.0950 - acc: 0.96 - ETA: 1:25:53 - loss: 0.0947 - acc: 0.96 - ETA: 1:23:57 - loss: 0.0944 - acc: 0.96 - ETA: 1:22:01 - loss: 0.0947 - acc: 0.96 - ETA: 1:20:06 - loss: 0.0945 - acc: 0.96 - ETA: 1:18:10 - loss: 0.0944 - acc: 0.96 - ETA: 1:16:15 - loss: 0.0950 - acc: 0.96 - ETA: 1:14:19 - loss: 0.0944 - acc: 0.96 - ETA: 1:12:24 - loss: 0.0945 - acc: 0.96 - ETA: 1:10:29 - loss: 0.0951 - acc: 0.96 - ETA: 1:08:34 - loss: 0.0952 - acc: 0.96 - ETA: 1:06:39 - loss: 0.0950 - acc: 0.96 - ETA: 1:04:45 - loss: 0.0954 - acc: 0.96 - ETA: 1:02:49 - loss: 0.0954 - acc: 0.96 - ETA: 1:00:54 - loss: 0.0957 - acc: 0.96 - ETA: 58:59 - loss: 0.0956 - acc: 0.9639 - ETA: 57:04 - loss: 0.0956 - acc: 0.96 - ETA: 55:09 - loss: 0.0954 - acc: 0.96 - ETA: 53:15 - loss: 0.0947 - acc: 0.96 - ETA: 51:21 - loss: 0.0947 - acc: 0.96 - ETA: 49:26 - loss: 0.0952 - acc: 0.96 - ETA: 47:32 - loss: 0.0950 - acc: 0.96 - ETA: 45:37 - loss: 0.0952 - acc: 0.96 - ETA: 43:43 - loss: 0.0954 - acc: 0.96 - ETA: 41:48 - loss: 0.0956 - acc: 0.96 - ETA: 39:53 - loss: 0.0956 - acc: 0.96 - ETA: 37:58 - loss: 0.0959 - acc: 0.96 - ETA: 36:03 - loss: 0.0966 - acc: 0.96 - ETA: 34:08 - loss: 0.0964 - acc: 0.96 - ETA: 32:14 - loss: 0.0966 - acc: 0.96 - ETA: 30:19 - loss: 0.0966 - acc: 0.96 - ETA: 28:24 - loss: 0.0970 - acc: 0.96 - ETA: 26:29 - loss: 0.0968 - acc: 0.96 - ETA: 24:34 - loss: 0.0969 - acc: 0.96 - ETA: 22:40 - loss: 0.0966 - acc: 0.96 - ETA: 20:45 - loss: 0.0965 - acc: 0.96 - ETA: 18:51 - loss: 0.0968 - acc: 0.96 - ETA: 16:56 - loss: 0.0967 - acc: 0.96 - ETA: 15:02 - loss: 0.0967 - acc: 0.96 - ETA: 13:07 - loss: 0.0974 - acc: 0.96 - ETA: 11:13 - loss: 0.0973 - acc: 0.96 - ETA: 9:18 - loss: 0.0969 - acc: 0.9636 - ETA: 7:24 - loss: 0.0971 - acc: 0.963 - ETA: 5:29 - loss: 0.0973 - acc: 0.963 - ETA: 3:34 - loss: 0.0974 - acc: 0.963 - ETA: 1:40 - loss: 0.0974 - acc: 0.963 - 9532s 168ms/step - loss: 0.0976 - acc: 0.9633 - val_loss: 0.2241 - val_acc: 0.9120\n",
      "Epoch 10/10\n",
      "56614/56614 [==============================] - ETA: 2:30:25 - loss: 0.0939 - acc: 0.96 - ETA: 2:28:41 - loss: 0.0940 - acc: 0.96 - ETA: 2:27:04 - loss: 0.0983 - acc: 0.96 - ETA: 2:25:16 - loss: 0.0944 - acc: 0.96 - ETA: 2:27:43 - loss: 0.0941 - acc: 0.96 - ETA: 2:25:04 - loss: 0.0949 - acc: 0.96 - ETA: 2:22:47 - loss: 0.0952 - acc: 0.96 - ETA: 2:20:33 - loss: 0.0960 - acc: 0.96 - ETA: 2:18:22 - loss: 0.0939 - acc: 0.96 - ETA: 2:16:14 - loss: 0.0923 - acc: 0.96 - ETA: 2:14:07 - loss: 0.0901 - acc: 0.96 - ETA: 2:12:05 - loss: 0.0915 - acc: 0.96 - ETA: 2:10:03 - loss: 0.0912 - acc: 0.96 - ETA: 2:08:01 - loss: 0.0904 - acc: 0.96 - ETA: 2:06:16 - loss: 0.0894 - acc: 0.96 - ETA: 2:04:30 - loss: 0.0889 - acc: 0.96 - ETA: 2:02:29 - loss: 0.0877 - acc: 0.96 - ETA: 2:00:30 - loss: 0.0882 - acc: 0.96 - ETA: 1:58:33 - loss: 0.0895 - acc: 0.96 - ETA: 1:56:39 - loss: 0.0881 - acc: 0.96 - ETA: 1:54:44 - loss: 0.0877 - acc: 0.96 - ETA: 1:52:48 - loss: 0.0878 - acc: 0.96 - ETA: 1:50:50 - loss: 0.0886 - acc: 0.96 - ETA: 1:48:54 - loss: 0.0882 - acc: 0.96 - ETA: 1:46:56 - loss: 0.0876 - acc: 0.96 - ETA: 1:45:00 - loss: 0.0885 - acc: 0.96 - ETA: 1:43:11 - loss: 0.0894 - acc: 0.96 - ETA: 1:41:14 - loss: 0.0891 - acc: 0.96 - ETA: 1:39:18 - loss: 0.0890 - acc: 0.96 - ETA: 1:37:22 - loss: 0.0894 - acc: 0.96 - ETA: 1:35:26 - loss: 0.0895 - acc: 0.96 - ETA: 1:33:29 - loss: 0.0892 - acc: 0.96 - ETA: 1:31:35 - loss: 0.0895 - acc: 0.96 - ETA: 1:29:38 - loss: 0.0903 - acc: 0.96 - ETA: 1:27:42 - loss: 0.0901 - acc: 0.96 - ETA: 1:25:47 - loss: 0.0894 - acc: 0.96 - ETA: 1:23:50 - loss: 0.0893 - acc: 0.96 - ETA: 1:21:56 - loss: 0.0891 - acc: 0.96 - ETA: 1:20:00 - loss: 0.0897 - acc: 0.96 - ETA: 1:18:04 - loss: 0.0897 - acc: 0.96 - ETA: 1:16:09 - loss: 0.0901 - acc: 0.96 - ETA: 1:14:14 - loss: 0.0903 - acc: 0.96 - ETA: 1:12:19 - loss: 0.0907 - acc: 0.96 - ETA: 1:10:23 - loss: 0.0907 - acc: 0.96 - ETA: 1:08:29 - loss: 0.0905 - acc: 0.96 - ETA: 1:06:33 - loss: 0.0902 - acc: 0.96 - ETA: 1:04:38 - loss: 0.0906 - acc: 0.96 - ETA: 1:02:43 - loss: 0.0906 - acc: 0.96 - ETA: 1:00:49 - loss: 0.0906 - acc: 0.96 - ETA: 58:54 - loss: 0.0907 - acc: 0.9660 - ETA: 56:59 - loss: 0.0909 - acc: 0.96 - ETA: 55:04 - loss: 0.0909 - acc: 0.96 - ETA: 53:09 - loss: 0.0907 - acc: 0.96 - ETA: 51:14 - loss: 0.0905 - acc: 0.96 - ETA: 49:20 - loss: 0.0908 - acc: 0.96 - ETA: 47:25 - loss: 0.0906 - acc: 0.96 - ETA: 45:32 - loss: 0.0905 - acc: 0.96 - ETA: 43:38 - loss: 0.0905 - acc: 0.96 - ETA: 41:44 - loss: 0.0904 - acc: 0.96 - ETA: 39:50 - loss: 0.0905 - acc: 0.96 - ETA: 37:56 - loss: 0.0908 - acc: 0.96 - ETA: 36:02 - loss: 0.0914 - acc: 0.96 - ETA: 34:07 - loss: 0.0913 - acc: 0.96 - ETA: 32:13 - loss: 0.0912 - acc: 0.96 - ETA: 30:19 - loss: 0.0913 - acc: 0.96 - ETA: 28:25 - loss: 0.0913 - acc: 0.96 - ETA: 26:31 - loss: 0.0914 - acc: 0.96 - ETA: 24:36 - loss: 0.0916 - acc: 0.96 - ETA: 22:42 - loss: 0.0917 - acc: 0.96 - ETA: 20:47 - loss: 0.0918 - acc: 0.96 - ETA: 18:53 - loss: 0.0918 - acc: 0.96 - ETA: 16:58 - loss: 0.0920 - acc: 0.96 - ETA: 15:04 - loss: 0.0917 - acc: 0.96 - ETA: 13:09 - loss: 0.0919 - acc: 0.96 - ETA: 11:14 - loss: 0.0918 - acc: 0.96 - ETA: 9:19 - loss: 0.0920 - acc: 0.9654 - ETA: 7:24 - loss: 0.0922 - acc: 0.965 - ETA: 5:30 - loss: 0.0922 - acc: 0.965 - ETA: 3:35 - loss: 0.0924 - acc: 0.965 - ETA: 1:40 - loss: 0.0925 - acc: 0.965 - 9567s 169ms/step - loss: 0.0926 - acc: 0.9653 - val_loss: 0.2764 - val_acc: 0.9114\n",
      "17693/17693 [==============================] - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 55s - ETA: 42 - ETA: 29 - ETA: 16 - ETA: 3 - 326s 18ms/step\n",
      "Test score: 0.28450374869610895\n",
      "Test accuracy: 0.9130164401955557\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_hist = model.fit(X_train_new, y_train, epochs=n_epochs, \n",
    "                   batch_size=batchsize, verbose=1, validation_data=(X_cv_new, y_cv))\n",
    "\n",
    "score = model.evaluate(X_test_new, y_test, batch_size=batchsize)\n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "final_output = final_output.append({\"Model\": 1,\n",
    "                                    \"Architecture\": 'Embedding-LSTM-Sigmoid', \n",
    "                                    \"TRAIN_LOSS\": '{:.5f}'.format(m_hist.history[\"loss\"][n_epochs-1]),\n",
    "                                    \"TEST_LOSS\": '{:.5f}'.format(score[0]),\n",
    "                                    \"TRAIN_ACC\": '{:.5f}'.format(m_hist.history[\"acc\"][n_epochs-1]),\n",
    "                                    \"TEST_ACC\": '{:.5f}'.format(score[1])}, ignore_index=True)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,n_epochs+1))\n",
    "\n",
    "vy = m_hist.history['val_loss']\n",
    "ty = m_hist.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------+\n",
      "| Layer | Epoch | Test Accuracy |\n",
      "+-------+-------+---------------+\n",
      "|   1   |   5   |     92.07     |\n",
      "|   2   |   10  |      91.3     |\n",
      "+-------+-------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Layer\", \"Epoch\", \"Test Accuracy\"]\n",
    "\n",
    "x.add_row([1, 5, 92.07])\n",
    "x.add_row([2, 10, 91.3])\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The LSTM model with '1' layer and '5' epochs hives us a higher test accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
